{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Project-Overview\" data-toc-modified-id=\"Project-Overview-1\">Project Overview</a></span><ul class=\"toc-item\"><li><span><a href=\"#Abstract\" data-toc-modified-id=\"Abstract-1.1\">Abstract</a></span></li><li><span><a href=\"#Note-on-revised-analysis\" data-toc-modified-id=\"Note-on-revised-analysis-1.2\">Note on revised analysis</a></span></li><li><span><a href=\"#Location-of-data-sets-and-guidance-on-how-to-get-started\" data-toc-modified-id=\"Location-of-data-sets-and-guidance-on-how-to-get-started-1.3\">Location of data sets and guidance on how to get started</a></span></li></ul></li><li><span><a href=\"#Phase-I:--Obtaining-and-Exploring-Data-per-DrivenData-Guidance\" data-toc-modified-id=\"Phase-I:--Obtaining-and-Exploring-Data-per-DrivenData-Guidance-2\">Phase I:  Obtaining and Exploring Data per DrivenData Guidance</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Set-Features\" data-toc-modified-id=\"Data-Set-Features-2.1\">Data Set Features</a></span></li><li><span><a href=\"#Data-Exploration\" data-toc-modified-id=\"Data-Exploration-2.2\">Data Exploration</a></span><ul class=\"toc-item\"><li><span><a href=\"#Training-Set\" data-toc-modified-id=\"Training-Set-2.2.1\">Training Set</a></span></li><li><span><a href=\"#Test-Set\" data-toc-modified-id=\"Test-Set-2.2.2\">Test Set</a></span></li><li><span><a href=\"#Training-labels\" data-toc-modified-id=\"Training-labels-2.2.3\">Training labels</a></span></li><li><span><a href=\"#Initial-data-exploration-observations\" data-toc-modified-id=\"Initial-data-exploration-observations-2.2.4\">Initial data exploration observations</a></span></li></ul></li><li><span><a href=\"#The-Error-Metric:--Top-10-Accuracy\" data-toc-modified-id=\"The-Error-Metric:--Top-10-Accuracy-2.3\">The Error Metric:  Top 10 Accuracy</a></span></li><li><span><a href=\"#Constructing-Features-from-DNA-Sequences\" data-toc-modified-id=\"Constructing-Features-from-DNA-Sequences-2.4\">Constructing Features from DNA Sequences</a></span></li><li><span><a href=\"#The-Error-Metric:--Top-10-Accuracy\" data-toc-modified-id=\"The-Error-Metric:--Top-10-Accuracy-2.5\">The Error Metric:  Top 10 Accuracy</a></span></li><li><span><a href=\"#Build-the-Model\" data-toc-modified-id=\"Build-the-Model-2.6\">Build the Model</a></span></li><li><span><a href=\"#Make-Predictions\" data-toc-modified-id=\"Make-Predictions-2.7\">Make Predictions</a></span></li></ul></li><li><span><a href=\"#Phase-II:-Building-on-DrivenData-Blog-Guidance\" data-toc-modified-id=\"Phase-II:-Building-on-DrivenData-Blog-Guidance-3\">Phase II: Building on DrivenData Blog Guidance</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Exploration\" data-toc-modified-id=\"Data-Exploration-3.1\">Data Exploration</a></span></li><li><span><a href=\"#Running-baseline-model-before-creating-features-from-DNA-sequences\" data-toc-modified-id=\"Running-baseline-model-before-creating-features-from-DNA-sequences-3.2\">Running baseline model before creating features from DNA sequences</a></span></li><li><span><a href=\"#Feature-Engineering-and-Model-Run:--3-bp-Sequences\" data-toc-modified-id=\"Feature-Engineering-and-Model-Run:--3-bp-Sequences-3.3\">Feature Engineering and Model Run:  3 bp Sequences</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-3-grams\" data-toc-modified-id=\"Creating-3-grams-3.3.1\">Creating 3-grams</a></span></li><li><span><a href=\"#Run-model-on-3-letter-DNA-sequences\" data-toc-modified-id=\"Run-model-on-3-letter-DNA-sequences-3.3.2\">Run model on 3-letter DNA sequences</a></span></li></ul></li><li><span><a href=\"#Feature-Engineering-and-Model-Run:--Commonly-Used-Sequences\" data-toc-modified-id=\"Feature-Engineering-and-Model-Run:--Commonly-Used-Sequences-3.4\">Feature Engineering and Model Run:  Commonly Used Sequences</a></span><ul class=\"toc-item\"><li><span><a href=\"#Additional-sequences-(e.g.,-RE-recognition-sites,-ORIs,-primers,-and-more)\" data-toc-modified-id=\"Additional-sequences-(e.g.,-RE-recognition-sites,-ORIs,-primers,-and-more)-3.4.1\">Additional sequences (e.g., RE recognition sites, ORIs, primers, and more)</a></span></li><li><span><a href=\"#Run-model-on-selected-DNA-sequences\" data-toc-modified-id=\"Run-model-on-selected-DNA-sequences-3.4.2\">Run model on selected DNA sequences</a></span></li></ul></li><li><span><a href=\"#Conclusion-from-running-Random-Forest-models-on-these-features\" data-toc-modified-id=\"Conclusion-from-running-Random-Forest-models-on-these-features-3.5\">Conclusion from running Random Forest models on these features</a></span></li></ul></li><li><span><a href=\"#Phase-III:--Exploring-Neural-Networks-(NNs)-as-a-Modeling-Tool\" data-toc-modified-id=\"Phase-III:--Exploring-Neural-Networks-(NNs)-as-a-Modeling-Tool-4\">Phase III:  Exploring Neural Networks (NNs) as a Modeling Tool</a></span><ul class=\"toc-item\"><li><span><a href=\"#Thought-process-when-considering-which-neural-network(s)-to-set-up-for-this-project\" data-toc-modified-id=\"Thought-process-when-considering-which-neural-network(s)-to-set-up-for-this-project-4.1\">Thought process when considering which neural network(s) to set up for this project</a></span><ul class=\"toc-item\"><li><span><a href=\"#How-are-DNA-sequences-similar-to-languages?\" data-toc-modified-id=\"How-are-DNA-sequences-similar-to-languages?-4.1.1\">How are DNA sequences similar to languages?</a></span></li><li><span><a href=\"#How-are-DNA-sequences-similar-to-images?\" data-toc-modified-id=\"How-are-DNA-sequences-similar-to-images?-4.1.2\">How are DNA sequences similar to images?</a></span></li></ul></li><li><span><a href=\"#CNN-model-setup\" data-toc-modified-id=\"CNN-model-setup-4.2\">CNN model setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Preprocessing-data\" data-toc-modified-id=\"Preprocessing-data-4.2.1\">Preprocessing data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Reducing-dataframe-size-to-increase-the-speed-of-training-models\" data-toc-modified-id=\"Reducing-dataframe-size-to-increase-the-speed-of-training-models-4.2.1.1\">Reducing dataframe size to increase the speed of training models</a></span></li><li><span><a href=\"#Character-level-vectorization:--values\" data-toc-modified-id=\"Character-level-vectorization:--values-4.2.1.2\">Character-level vectorization:  values</a></span></li><li><span><a href=\"#Train_test_split-on-this-data-for-validation\" data-toc-modified-id=\"Train_test_split-on-this-data-for-validation-4.2.1.3\">Train_test_split on this data for validation</a></span></li><li><span><a href=\"#Compute-class-weights-for-training-dataset\" data-toc-modified-id=\"Compute-class-weights-for-training-dataset-4.2.1.4\">Compute class weights for training dataset</a></span></li></ul></li></ul></li><li><span><a href=\"#1D-CNN-Models-using-data-subset-of-sequences\" data-toc-modified-id=\"1D-CNN-Models-using-data-subset-of-sequences-4.3\">1D CNN Models using data subset of sequences</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model:--labs-submitting-at-least-200-plasmids\" data-toc-modified-id=\"Model:--labs-submitting-at-least-200-plasmids-4.3.1\">Model:  labs submitting at least 200 plasmids</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-setup\" data-toc-modified-id=\"Model-setup-4.3.1.1\">Model setup</a></span></li><li><span><a href=\"#Model-compile\" data-toc-modified-id=\"Model-compile-4.3.1.2\">Model compile</a></span></li><li><span><a href=\"#Model-fit\" data-toc-modified-id=\"Model-fit-4.3.1.3\">Model fit</a></span></li><li><span><a href=\"#Visualizations\" data-toc-modified-id=\"Visualizations-4.3.1.4\">Visualizations</a></span></li><li><span><a href=\"#Save-model\" data-toc-modified-id=\"Save-model-4.3.1.5\">Save model</a></span></li><li><span><a href=\"#Observations-about-model\" data-toc-modified-id=\"Observations-about-model-4.3.1.6\">Observations about model</a></span></li></ul></li><li><span><a href=\"#Model_a:--labs-submitting-at-least-200-plasmids--changing-number-of-filters\" data-toc-modified-id=\"Model_a:--labs-submitting-at-least-200-plasmids--changing-number-of-filters-4.3.2\">Model_a:  labs submitting at least 200 plasmids--changing number of filters</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-setup:--changing-from-32-filters-to-64-filters;-kernel-size-same,-still-8500-max-characters-per-plasmid\" data-toc-modified-id=\"Model-setup:--changing-from-32-filters-to-64-filters;-kernel-size-same,-still-8500-max-characters-per-plasmid-4.3.2.1\">Model setup:  changing from 32 filters to 64 filters; kernel size same, still 8500 max characters per plasmid</a></span></li><li><span><a href=\"#Model-compile\" data-toc-modified-id=\"Model-compile-4.3.2.2\">Model compile</a></span></li><li><span><a href=\"#Model-fit\" data-toc-modified-id=\"Model-fit-4.3.2.3\">Model fit</a></span></li><li><span><a href=\"#Visualizations\" data-toc-modified-id=\"Visualizations-4.3.2.4\">Visualizations</a></span></li><li><span><a href=\"#Save-model\" data-toc-modified-id=\"Save-model-4.3.2.5\">Save model</a></span></li><li><span><a href=\"#Observations-about-model\" data-toc-modified-id=\"Observations-about-model-4.3.2.6\">Observations about model</a></span></li></ul></li><li><span><a href=\"#Model_1:--labs-submitting-at-least-200-plasmids-each--changing-pooling-layers;-adding-dropout-layers\" data-toc-modified-id=\"Model_1:--labs-submitting-at-least-200-plasmids-each--changing-pooling-layers;-adding-dropout-layers-4.3.3\">Model_1:  labs submitting at least 200 plasmids each--changing pooling layers; adding dropout layers</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-setup--switching-to-MaxPooling1D;-adding-dropout-layers;-still-8500-characters-max\" data-toc-modified-id=\"Model-setup--switching-to-MaxPooling1D;-adding-dropout-layers;-still-8500-characters-max-4.3.3.1\">Model setup--switching to MaxPooling1D; adding dropout layers; still 8500 characters max</a></span></li><li><span><a href=\"#Model-compile\" data-toc-modified-id=\"Model-compile-4.3.3.2\">Model compile</a></span></li><li><span><a href=\"#Model-fit\" data-toc-modified-id=\"Model-fit-4.3.3.3\">Model fit</a></span></li><li><span><a href=\"#Visualizations\" data-toc-modified-id=\"Visualizations-4.3.3.4\">Visualizations</a></span></li><li><span><a href=\"#Save-model\" data-toc-modified-id=\"Save-model-4.3.3.5\">Save model</a></span></li><li><span><a href=\"#Observations-about-model\" data-toc-modified-id=\"Observations-about-model-4.3.3.6\">Observations about model</a></span></li></ul></li><li><span><a href=\"#Model_1b:--labs-submitting-at-least-200-plasmids-each--changing-Dense-layer-connections\" data-toc-modified-id=\"Model_1b:--labs-submitting-at-least-200-plasmids-each--changing-Dense-layer-connections-4.3.4\">Model_1b:  labs submitting at least 200 plasmids each--changing Dense layer connections</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-setup--changing-1st-Dense-layer-from-64-to-128;-still-8500-characters-max\" data-toc-modified-id=\"Model-setup--changing-1st-Dense-layer-from-64-to-128;-still-8500-characters-max-4.3.4.1\">Model setup--changing 1st Dense layer from 64 to 128; still 8500 characters max</a></span></li><li><span><a href=\"#Model-compile\" data-toc-modified-id=\"Model-compile-4.3.4.2\">Model compile</a></span></li><li><span><a href=\"#Model-fit\" data-toc-modified-id=\"Model-fit-4.3.4.3\">Model fit</a></span></li><li><span><a href=\"#Visualizations\" data-toc-modified-id=\"Visualizations-4.3.4.4\">Visualizations</a></span></li><li><span><a href=\"#Save-model\" data-toc-modified-id=\"Save-model-4.3.4.5\">Save model</a></span></li><li><span><a href=\"#Observations-about-model\" data-toc-modified-id=\"Observations-about-model-4.3.4.6\">Observations about model</a></span></li></ul></li><li><span><a href=\"#Model_1c:--Increasing-max_char-to-10000-and-adding-dropout-layers\" data-toc-modified-id=\"Model_1c:--Increasing-max_char-to-10000-and-adding-dropout-layers-4.3.5\">Model_1c:  Increasing max_char to 10000 and adding dropout layers</a></span><ul class=\"toc-item\"><li><span><a href=\"#Character-level-vectorization:--values\" data-toc-modified-id=\"Character-level-vectorization:--values-4.3.5.1\">Character-level vectorization:  values</a></span></li><li><span><a href=\"#Train_test_split\" data-toc-modified-id=\"Train_test_split-4.3.5.2\">Train_test_split</a></span></li><li><span><a href=\"#Define-model_1c\" data-toc-modified-id=\"Define-model_1c-4.3.5.3\">Define model_1c</a></span></li><li><span><a href=\"#Model-fit\" data-toc-modified-id=\"Model-fit-4.3.5.4\">Model fit</a></span></li><li><span><a href=\"#Visualizations\" data-toc-modified-id=\"Visualizations-4.3.5.5\">Visualizations</a></span></li><li><span><a href=\"#Save-model\" data-toc-modified-id=\"Save-model-4.3.5.6\">Save model</a></span></li><li><span><a href=\"#Observations-about-model_1c\" data-toc-modified-id=\"Observations-about-model_1c-4.3.5.7\">Observations about model_1c</a></span></li></ul></li><li><span><a href=\"#Observations-from-first-runs-of-Conv1D-models\" data-toc-modified-id=\"Observations-from-first-runs-of-Conv1D-models-4.3.6\">Observations from first runs of Conv1D models</a></span></li><li><span><a href=\"#Model_2:--labs-summitting-50-or-fewer-plasmids-each\" data-toc-modified-id=\"Model_2:--labs-summitting-50-or-fewer-plasmids-each-4.3.7\">Model_2:  labs summitting 50 or fewer plasmids each</a></span><ul class=\"toc-item\"><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-4.3.7.1\">Preprocessing</a></span></li><li><span><a href=\"#Character-level-vectorization:--values\" data-toc-modified-id=\"Character-level-vectorization:--values-4.3.7.2\">Character-level vectorization:  values</a></span></li><li><span><a href=\"#Model-setup\" data-toc-modified-id=\"Model-setup-4.3.7.3\">Model setup</a></span></li><li><span><a href=\"#Model-compile\" data-toc-modified-id=\"Model-compile-4.3.7.4\">Model compile</a></span></li><li><span><a href=\"#Model-fit\" data-toc-modified-id=\"Model-fit-4.3.7.5\">Model fit</a></span></li><li><span><a href=\"#Visualizations\" data-toc-modified-id=\"Visualizations-4.3.7.6\">Visualizations</a></span></li><li><span><a href=\"#Save-model\" data-toc-modified-id=\"Save-model-4.3.7.7\">Save model</a></span></li><li><span><a href=\"#Observations-about-model_2\" data-toc-modified-id=\"Observations-about-model_2-4.3.7.8\">Observations about model_2</a></span></li></ul></li><li><span><a href=\"#Model_3:--labs-submitting-10-or-fewer-plasmids-each\" data-toc-modified-id=\"Model_3:--labs-submitting-10-or-fewer-plasmids-each-4.3.8\">Model_3:  labs submitting 10 or fewer plasmids each</a></span><ul class=\"toc-item\"><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-4.3.8.1\">Preprocessing</a></span></li><li><span><a href=\"#Model-setup\" data-toc-modified-id=\"Model-setup-4.3.8.2\">Model setup</a></span></li><li><span><a href=\"#Model-compile\" data-toc-modified-id=\"Model-compile-4.3.8.3\">Model compile</a></span></li><li><span><a href=\"#Model-fit\" data-toc-modified-id=\"Model-fit-4.3.8.4\">Model fit</a></span></li><li><span><a href=\"#Visualizations\" data-toc-modified-id=\"Visualizations-4.3.8.5\">Visualizations</a></span></li><li><span><a href=\"#Save-model\" data-toc-modified-id=\"Save-model-4.3.8.6\">Save model</a></span></li><li><span><a href=\"#Observations-about-model_3\" data-toc-modified-id=\"Observations-about-model_3-4.3.8.7\">Observations about model_3</a></span></li></ul></li><li><span><a href=\"#Model_4:--plasmids-submitted--between-10-and-50\" data-toc-modified-id=\"Model_4:--plasmids-submitted--between-10-and-50-4.3.9\">Model_4:  plasmids submitted--between 10 and 50</a></span><ul class=\"toc-item\"><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-4.3.9.1\">Preprocessing</a></span></li><li><span><a href=\"#Model_4-setup\" data-toc-modified-id=\"Model_4-setup-4.3.9.2\">Model_4 setup</a></span></li><li><span><a href=\"#Model-compile\" data-toc-modified-id=\"Model-compile-4.3.9.3\">Model compile</a></span></li><li><span><a href=\"#Model-fit\" data-toc-modified-id=\"Model-fit-4.3.9.4\">Model fit</a></span></li><li><span><a href=\"#Visualizations\" data-toc-modified-id=\"Visualizations-4.3.9.5\">Visualizations</a></span></li><li><span><a href=\"#Save-model\" data-toc-modified-id=\"Save-model-4.3.9.6\">Save model</a></span></li><li><span><a href=\"#Observations-about-model_4\" data-toc-modified-id=\"Observations-about-model_4-4.3.9.7\">Observations about model_4</a></span></li></ul></li><li><span><a href=\"#Model_4a:--plasmids-submitted--between-10-and-50;-dropout-layers-added\" data-toc-modified-id=\"Model_4a:--plasmids-submitted--between-10-and-50;-dropout-layers-added-4.3.10\">Model_4a:  plasmids submitted--between 10 and 50; dropout layers added</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model_4a-setup\" data-toc-modified-id=\"Model_4a-setup-4.3.10.1\">Model_4a setup</a></span></li><li><span><a href=\"#Model-compile\" data-toc-modified-id=\"Model-compile-4.3.10.2\">Model compile</a></span></li><li><span><a href=\"#Model-fit\" data-toc-modified-id=\"Model-fit-4.3.10.3\">Model fit</a></span></li><li><span><a href=\"#Visualizations\" data-toc-modified-id=\"Visualizations-4.3.10.4\">Visualizations</a></span></li><li><span><a href=\"#Save-model\" data-toc-modified-id=\"Save-model-4.3.10.5\">Save model</a></span></li><li><span><a href=\"#Observations-about-model_4a\" data-toc-modified-id=\"Observations-about-model_4a-4.3.10.6\">Observations about model_4a</a></span></li></ul></li><li><span><a href=\"#Model_5:--plasmid-length-less-than-15000\" data-toc-modified-id=\"Model_5:--plasmid-length-less-than-15000-4.3.11\">Model_5:  plasmid length less than 15000</a></span><ul class=\"toc-item\"><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-4.3.11.1\">Preprocessing</a></span></li><li><span><a href=\"#Model-compile\" data-toc-modified-id=\"Model-compile-4.3.11.2\">Model compile</a></span></li><li><span><a href=\"#Model-Summary\" data-toc-modified-id=\"Model-Summary-4.3.11.3\">Model Summary</a></span></li><li><span><a href=\"#Model-fit\" data-toc-modified-id=\"Model-fit-4.3.11.4\">Model fit</a></span></li><li><span><a href=\"#Visualizations\" data-toc-modified-id=\"Visualizations-4.3.11.5\">Visualizations</a></span></li><li><span><a href=\"#Save-model\" data-toc-modified-id=\"Save-model-4.3.11.6\">Save model</a></span></li><li><span><a href=\"#Observations-about-model\" data-toc-modified-id=\"Observations-about-model-4.3.11.7\">Observations about model</a></span></li></ul></li></ul></li><li><span><a href=\"#Model-Results-and-Observations\" data-toc-modified-id=\"Model-Results-and-Observations-4.4\">Model Results and Observations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Original-analysis-(code-for-these-models-can-be-found-in-the-Appendix)\" data-toc-modified-id=\"Original-analysis-(code-for-these-models-can-be-found-in-the-Appendix)-4.4.1\">Original analysis (code for these models can be found in the Appendix)</a></span></li></ul></li><li><span><a href=\"#Updated-models\" data-toc-modified-id=\"Updated-models-4.5\">Updated models</a></span></li></ul></li><li><span><a href=\"#Conclusions-and-Future-Work\" data-toc-modified-id=\"Conclusions-and-Future-Work-5\">Conclusions and Future Work</a></span><ul class=\"toc-item\"><li><span><a href=\"#Conclusions-from-original-analysis\" data-toc-modified-id=\"Conclusions-from-original-analysis-5.1\">Conclusions from original analysis</a></span></li><li><span><a href=\"#Conclusions-for-updated-models\" data-toc-modified-id=\"Conclusions-for-updated-models-5.2\">Conclusions for updated models</a></span></li></ul></li><li><span><a href=\"#Appendix\" data-toc-modified-id=\"Appendix-6\">Appendix</a></span><ul class=\"toc-item\"><li><span><a href=\"#Models-from-Original-Capstone-Project\" data-toc-modified-id=\"Models-from-Original-Capstone-Project-6.1\">Models from Original Capstone Project</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model_4:--Increasing-max_char-to-10000-and-using-smaller-filter-numbers\" data-toc-modified-id=\"Model_4:--Increasing-max_char-to-10000-and-using-smaller-filter-numbers-6.1.1\">Model_4:  Increasing max_char to 10000 and using smaller filter numbers</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setting-max_length-of-characters-in-sequences-and-tokenizing\" data-toc-modified-id=\"Setting-max_length-of-characters-in-sequences-and-tokenizing-6.1.1.1\">Setting max_length of characters in sequences and tokenizing</a></span></li><li><span><a href=\"#Train_test_split\" data-toc-modified-id=\"Train_test_split-6.1.1.2\">Train_test_split</a></span></li><li><span><a href=\"#Define-model_4\" data-toc-modified-id=\"Define-model_4-6.1.1.3\">Define model_4</a></span></li><li><span><a href=\"#Visualizations\" data-toc-modified-id=\"Visualizations-6.1.1.4\">Visualizations</a></span></li><li><span><a href=\"#Observations-about-model_4\" data-toc-modified-id=\"Observations-about-model_4-6.1.1.5\">Observations about model_4</a></span></li></ul></li><li><span><a href=\"#Model_5:--Adding-another-convolution-layer-to-each-of-the-two-conv1D-layer-stacks-and-reducing-kernel-size\" data-toc-modified-id=\"Model_5:--Adding-another-convolution-layer-to-each-of-the-two-conv1D-layer-stacks-and-reducing-kernel-size-6.1.2\">Model_5:  Adding another convolution layer to each of the two conv1D layer stacks and reducing kernel size</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-model_5\" data-toc-modified-id=\"Define-model_5-6.1.2.1\">Define model_5</a></span></li><li><span><a href=\"#Visualizations\" data-toc-modified-id=\"Visualizations-6.1.2.2\">Visualizations</a></span></li><li><span><a href=\"#Observations-about-model_5\" data-toc-modified-id=\"Observations-about-model_5-6.1.2.3\">Observations about model_5</a></span></li></ul></li><li><span><a href=\"#Model_6:--Increasing-max_char-to-20000-and-using-smaller-filter-numbers\" data-toc-modified-id=\"Model_6:--Increasing-max_char-to-20000-and-using-smaller-filter-numbers-6.1.3\">Model_6:  Increasing max_char to 20000 and using smaller filter numbers</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setting-max_length-of-characters-in-sequences-and-tokenizing\" data-toc-modified-id=\"Setting-max_length-of-characters-in-sequences-and-tokenizing-6.1.3.1\">Setting max_length of characters in sequences and tokenizing</a></span></li><li><span><a href=\"#Train_test_split\" data-toc-modified-id=\"Train_test_split-6.1.3.2\">Train_test_split</a></span></li><li><span><a href=\"#Define-model_6\" data-toc-modified-id=\"Define-model_6-6.1.3.3\">Define model_6</a></span></li><li><span><a href=\"#Visualizations\" data-toc-modified-id=\"Visualizations-6.1.3.4\">Visualizations</a></span></li><li><span><a href=\"#Observations-about-model_6\" data-toc-modified-id=\"Observations-about-model_6-6.1.3.5\">Observations about model_6</a></span></li></ul></li></ul></li><li><span><a href=\"#Option-to-run-existing-model(s)\" data-toc-modified-id=\"Option-to-run-existing-model(s)-6.2\">Option to run existing model(s)</a></span></li><li><span><a href=\"#Probabilities-and-top-10-lab-probabilities-for-each-result\" data-toc-modified-id=\"Probabilities-and-top-10-lab-probabilities-for-each-result-6.3\">Probabilities and top 10 lab probabilities for each result</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "\n",
    "For my Flatiron data science capstone project, I chose to use a dataset from a data science competition hosted by DrivenData and altlabs (a non-profit firm committed to responsible development and use of genetic engineering tools) for algorithms to predict the labs-of-origin for DNA constructs called plasmids.  \n",
    "\n",
    "While there were a few published research papers available when I began working on this project, I wanted to start the project with a relatively clean slate--reviewing the techniques I had learned during the program, getting my instructors' thoughts, and developing a relatively simple first draft.  It was through this process that I decided to start with a 1D CNN model, moving on to a Recurrent Neural Network (RNN) with LSTM if time permitted.  \n",
    "\n",
    "Researching this topic also allowed me to both revisit the molecular biology (which I studied in college and gained updated knowledge about in my last job at a research university) and to learn much more about deep learning and AI than I would have otherwise in my data science program.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "This project is focused on exploring modeling techniques to predict the labs-of-origin for DNA constructs called plasmids.  The problem statement and data are from a  data science competition, sponsored by altLabs and hosted by DrivenData, called the Genetic Engineering Attribution Challenge (GEAC).  This rather unique and challenging problem involves analyzing DNA plasmids for clues about who made them.  As I explain later in the notebook, the way information is encoded in DNA makes this problem particularly challenging; there are some similarities with Natural Language Processing (NLP) and also with image recognition, but there are some significant differences as well (particularly with NLP).  \n",
    "\n",
    "Plasmids have been used for decades in molecular cloning applications and are critically important to both research activities and industrial production.  However, the increasing availability of advanced methods and tools for genetic engineering raises the specter of potential harm due to unintended or malicious activities by a broader range of people.  Thus, the development of tools that can correctly identify the lab of origin for a given plasmid is becoming ever more important and urgent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note on revised analysis\n",
    "\n",
    "In July 2021, I decided to revisit the project, to update the code for this project to run Tensorflow 2.5 and python 3.9 natively on my M1 MacBook Air.  I also explored some approaches to feeding batches of variable-length sequence data into the 1D CNN, but experienced some technical challenges and went back to my original approach in the interests of time.  I purposely chose _not_ to revisit the DrivenData GEAC competition website until completing the steps above.  My findings are summarized at the end of this notebook. \n",
    "\n",
    "Subsequent to updating the code in my notebook, I checked out the winning GEAC competition projects.  Perhaps it's a good thing that this information was not available when I started:  the advanced algorithms employed by the winner--a computational biologist--are pretty intimidating, and I might have decided to pursue a different project.  But I learned so much about various modeling approaches (most especially 1DCNN and RNN with LSTM), coding in Tensorflow 2.5, and even just successfully setting up the conda environment for the M1 MacBook Air (which was a bit more complicated than usual) that it was worth it.  All in all, it has been a very interesting project, and I am excited to apply what I've learned to new challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location of data sets and guidance on how to get started\n",
    "\n",
    "* The data sets provided by the competition organizers are too large to be hosted on github.  The required .csv files at https://www.drivendata.org/competitions/63/genetic-engineering-attribution/page/164/.  Login is require, but accounts are free and easy to set up.   \n",
    "\n",
    "* The DrivenData website for this competition features a blog post that provides guidance and starter code to participants, so that everyone is able to access the data and format submissions properly.  I used this code as a starting point, but this project involved much more work beyond that done in the blog post.  The blog is available at https://www.drivendata.co/blog/genetic-attribution-benchmark/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase I:  Obtaining and Exploring Data per DrivenData Guidance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_From the blog post \"Benchmark\" at https://www.drivendata.co/blog/genetic-attribution-benchmark/_\n",
    "\n",
    "TUE 18 AUGUST 2020\n",
    "by CHRISTINE CHUNG\n",
    "\n",
    "Genetic engineering is a powerful tool with a wide array of applications. It's being used to do everything from creating safe alternatives to pesticides to producing critical ingredients for medicines and industry. However, it's rise and increasing accessibility also comes with the potential for lab accidents, purposeful wrongdoing, and abuse.\n",
    "\n",
    "Genetic engineering attribution is a tool that can help promote accountability and deter bad actors. In our newest competition, we're asking you to to create an algorithm that identifies the lab-of-origin for genetically engineered DNA—with the highest accuracy level possible. The metric for this competition is top ten accuracy.\n",
    "\n",
    "The DNA for this challenge comes from an online dataset of plasmids. Plasmids are small, circular DNA molecules that replicate independently from chromosomes. Plasmids used commonly in research come from cells in mammals, bacteria, worms, yeast, and insects. Plasmid information can be uploaded and accessed digitally thanks to AddGene, a large, non-profit plasmid repository based in Watertown, MA.\n",
    "\n",
    "In this benchmark, we'll cover how to:\n",
    "\n",
    "* load the data\n",
    "* create text-based features from DNA sequences\n",
    "* train a random forest model and make predictions\n",
    "* create a custom scorer based on top-ten accuracy\n",
    "* submit predictions to the competition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set Features\n",
    "\n",
    "There are 41 columns in this dataset. Each row corresponds to a plasmid DNA sequence, which is uniquely identified by sequence_id, a 5-character alphanumeric string. In addition to the DNA sequences provided in sequence, there are 39 binary features that provide metadata about the plasmids. All variables are described below.\n",
    "\n",
    "* ```sequence``` (type: string): A plasmid DNA sequence. Any Us were changed to Ts and letters other than A, T, G, C, or N were changed to Ns. Possible values: A, T, G, C, or N\n",
    "* ```bacterial_resistance_ampicillin```, ```bacterial_resistance_chloramphenicol```, ```bacterial_resistance_kanamycin```, ```bacterial_resistance_other```, ```bacterial_resistance_spectinomycin``` (type: binary): One-hot encoded columns that indicate the antibiotic resistance of the plasmid used for selecting during bacterial growth and cloning.\n",
    "* ```copy_number_high_copy```, ```copy_number_low_copy```, ```copy_number_unknown``` (type: binary): One-hot encoded columns that indicate the number of plasmids per bacterial cell.\n",
    "* ```growth_strain_ccdb_survival```, ```growth_strain_dh10b```, ```growth_strain_dh5alpha```, ```growth_strain_neb_stable```, ```growth_strain_other```, ```growth_strain_stbl3```, ```growth_strain_top10```, ```growth_strain_xl1_blue``` (type: binary): One-hot encoded columns that indicate the strain used to clone the plasmid.\n",
    "* ```growth_temp_30```, ```growth_temp_37```, ```growth_temp_other``` (type: binary): One-hot encoded columns that indicate the temperature the plasmid should be grown at.\n",
    "* ```selectable_markers_blasticidin```, ```selectable_markers_his3```, ```selectable_markers_hygromycin```, ```selectable_markers_leu2```, ```selectable_markers_neomycin```, ```selectable_markers_other```, ```selectable_markers_puromycin```, ```selectable_markers_trp1```, ```selectable_markers_ura3```, ```selectable_markers_zeocin``` (type: binary): One-hot encoded columns that indicate genes that allow non-bacterial selection (for a plasmid used outside of the cloning organism).\n",
    "* ```species_budding_yeast```, ```species_fly```, ```species_human```, ```species_mouse```, ```species_mustard_weed```, ```species_nematode```, ```species_other```, ```species_rat```, ```species_synthetic```, ```species_zebrafish``` (type: binary): One-hot encoded columns that indicate the species the plasmid is used in, after cloning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "np.random.seed(42)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values = pd.read_csv('data/altlabs_train_values.csv', index_col='sequence_id')\n",
    "train_labels = pd.read_csv('data/altlabs_train_labels.csv', index_col='sequence_id')\n",
    "test_values = pd.read_csv('data/altlabs_test_values.csv', index_col='sequence_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_lengths = train_values.sequence.apply(len)\n",
    "sequence_lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_lengths.plot(kind = 'hist', color='purple', bins=100, fontsize=14, figsize=(12,5))\n",
    "plt.title('Distribution of plasmid lengths', fontsize=18)\n",
    "plt.xlabel('Length of Plasmid', fontsize=16)\n",
    "plt.ylabel('Number of Plasmids', fontsize=16);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_sequence_lengths = sequence_lengths.sort_values(ascending=True)\n",
    "sorted_sequence_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pandas.set_option('display.max_rows', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_sequence_lengths[-120:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_sequence_lengths[54000:63017].plot(kind = 'hist', color='purple', title='Distribution of plasmid lengths', \n",
    "                            bins=100, xlim=(8000, 25000));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_seq = train_values['sequence'].loc['7PXUZ']\n",
    "len(longest_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_seq.count('N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_seq = train_values['sequence'].loc['CSLKO']\n",
    "len(token_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_seq.count('N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing remaining columns, which are one-hot encoded\n",
    "\n",
    "train_values.iloc[:, 1:].apply(pd.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_binary_features = train_values.iloc[:, 1:].mean().sort_values()\n",
    "\n",
    "ax = sorted_binary_features.plot(kind = 'barh', color='purple', stacked=True, figsize=(5, 12), title='Prevalence of binary features')\n",
    "\n",
    "ax.set_xlabel('Proportion of Sequences');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values.sequence.apply(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the evaluation of training labels simpler, we'll collapse them into one column, 'lab_ids'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ids = pd.DataFrame(train_labels.idxmax(axis=1), columns=['lab_id'])\n",
    "lab_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ids.lab_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ids.lab_id.value_counts().plot(kind='hist', color='purple', bins=100, figsize=(12, 5), fontsize=14)\n",
    "plt.title(\"Number of plasmids contributed, by lab\", fontsize=18)\n",
    "plt.xlabel(\"Plasmids contributed by lab\", fontsize=16)\n",
    "plt.ylabel(\"Count of labs contributing amount\", fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting number of plasmids by number of labs contributing that amount is not very useful--other than to show us that a small percentage of labs contribute the majority of plasmids.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:  labs can have anywhere from 1 to > 8000 sequences in this data set.  Using ```describe()```, we can see that the mean number of sequences/plasmids per lab in this data set is ~48.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ids.lab_id.value_counts().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see that the mean of 48 is quite a bit higher than the number of plasmids contributed by labs below the 75th percentile--suggesting that the vast majority of labs have contributed very few plamids, while a small percentage of labs contribute the majority of plasmids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ids.lab_id.value_counts().describe().plot(kind='hist', color='purple', bins=100, figsize=(14,5), fontsize=14)\n",
    "plt.title(\"Frequency of labs contributing 'N' number of plasmids\", fontsize=18)\n",
    "plt.xlabel(\"Number of plasmids contributed by lab ('N')\", fontsize=16)\n",
    "plt.ylabel(\"Percentile of labs contributing 'N' (e.g., 5 = 50%)\", fontsize=16, );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that about 50% of labs contribute less than ~100 plasmids each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ids.lab_id.value_counts().plot(kind='hist', color='purple', bins=1000, figsize=(12,5), fontsize=14, xlim=(0, 100))\n",
    "plt.title(\"Number of labs contributing 'N' == 100 plasmids or less\", fontsize=18)\n",
    "plt.xlabel(\"Number of plasmids contributed by lab ('N')\", fontsize=16)\n",
    "plt.ylabel(\"Count of labs contributing 'N' plasmids\", fontsize=16);\n",
    "\n",
    "lab_ids.lab_id.value_counts(ascending=False)[95:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ids.lab_id.value_counts().plot(kind='hist', color='purple', bins=1000, figsize=(12,5), fontsize=14, xlim=(0, 200))\n",
    "plt.title(\"Number of labs contributing 'N' >= 200 plasmids each\", fontsize=18)\n",
    "plt.xlabel(\"Number of plasmids contributed by lab ('N')\", fontsize=16)\n",
    "plt.ylabel(\"Count of labs contributing 'N'\", fontsize=16);\n",
    "\n",
    "lab_ids.lab_id.value_counts(ascending=False)[42:]  # 1272 labs contributed less than 200 plasmids each\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ids.lab_id.value_counts()[:50].plot(kind='hist', color='purple', bins=100, figsize=(12,5), fontsize=14)\n",
    "plt.title(\"Top 50 highest-contributing labs\", fontsize=18)\n",
    "plt.xlabel(\"Number of plasmids contributed by lab\", fontsize=16)\n",
    "plt.ylabel(\"Count of labs contributing at this level\", fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ids.lab_id.value_counts().sort_values(ascending=True)[1217:]    # each lab from the 1,217th lab to the 1,314th \n",
    "                                                                    # lab has contributed at least 100 plasmids\n",
    "                                                                    # Thus, the top 97 labs contributed 100 or more\n",
    "                                                                    # plasmids each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ids.lab_id.value_counts().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting labs by their prevalence of sequences in the data, we can see that lab I7FXTVDP is the most heavily represented, producing just over 13% of the sequences in this dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_contr_pcts = lab_ids['lab_id'].value_counts(normalize=True).sort_values(ascending=False).head(10)\n",
    "top_contr_pcts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking just at the top 50 labs, we see a dramatic dropoff in the number of sequences contributed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ids.lab_id.value_counts()[:50].plot(kind='hist', color='purple', bins=100, figsize=(12, 4), fontsize=14)\n",
    "plt.title(\"Number of plasmids contributed by lab (top 50 contributing labs)\",  fontsize=18)\n",
    "plt.xlabel(\"Plasmids contributed\",  fontsize=16)\n",
    "plt.ylabel(\"Number of labs\",   fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ids.lab_id.value_counts()[:50].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting labs by their prevalence of sequences in the data, we can see that lab I7FXTVDP is the most heavily represented, producing just over 13% of the sequences in this dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_contr_pcts = lab_ids['lab_id'].value_counts(normalize=True).sort_values(ascending=False).head(10)\n",
    "top_contr_pcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ids['lab_id'].value_counts(normalize=True).sort_values(ascending=False).head(10).sum()\n",
    "\n",
    "# Ten labs contribute just over 30% of all plasmids to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial data exploration observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two key elements of this dataset present challenges:  the variability in the length of DNA sequences (from 20 to over 60,000) and the non-uniformity of number of sequence contributions per lab (from 1 sequence to over 8900).  Whether using machine learning ensemble methods or neural networks, addressing these issues will be necessary to manage modeling complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Error Metric:  Top 10 Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NOTE:  All text in this section is verbatim from the Benchmark blog posting for this competition.  The purpose of this blog is to guide participants in the competition through the initial set-up stages of the modeling._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The goal for this competition is to help narrow down the field of possible labs-of-origin from thousands to just a few. To that end, predictions will be evaluated based on top-ten accuracy. That means we'll consider a prediction \"correct\" if the true lab-of-origin is in the top ten most likely labs.\n",
    "\n",
    "There is not a built in evaluation metric for top-k accuracy in scikit-learn, so we'll be constructing a custom scorer. We'll use this to determine the final accuracy of our model.\n",
    "\n",
    "First, we'll need to create a custom scorer that can take in an estimator, validation data, and labels, and output a score based on the top ten results from each predicton. Scikit-learn lets us do this if we adhere to a specific signature.\n",
    "\n",
    "From the scikit-learn documentation:\n",
    "\n",
    "    For a callable to be a scorer, it needs to meet the protocol specified by the following two rules:\n",
    "\n",
    "    It can be called with parameters (estimator, X, y), where estimator is the model that should be evaluated, X is validation data, and y is the ground truth target for X (in the supervised case) or None (in the unsupervised case).\n",
    "\n",
    "    It returns a floating point number that quantifies the estimator prediction quality on X, with reference to y. Again, by convention higher numbers are better, so if your scorer returns loss, that value should be negated.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top10_accuracy_scorer(estimator, X, y):\n",
    "    '''\n",
    "    A custom scorer that evaluates a model on whether the correct label is in \n",
    "    the top 10 most probable predictions.\n",
    "\n",
    "    Args:\n",
    "        estimator (sklearn estimator): The sklearn model that should be evaluated.\n",
    "        X (numpy array): The validation data.\n",
    "        y (numpy array): The ground truth labels.\n",
    "\n",
    "    Returns:\n",
    "        float: Accuracy of the model as defined by the proportion of predictions\n",
    "               in which the correct label was in the top 10. Higher is better.\n",
    "    '''\n",
    "    \n",
    "    # predict the probabilities across all possible labels for rows in our training set\n",
    "    probas = estimator.predict_proba(X)\n",
    "    \n",
    "    # get the indices for top 10 predictions for each row; these are the last ten in each row\n",
    "    \n",
    "    # Note: We use argpartition, which is O(n), vs argsort, which uses the quicksort algorithm \n",
    "    # by default and is O(n^2) in the worst case. We can do this because we only need the top ten\n",
    "    # partitioned, not in sorted order.\n",
    "    # Documentation: https://numpy.org/doc/1.18/reference/generated/numpy.argpartition.html\n",
    "    top10_idx = np.argpartition(probas, -10, axis=1)[:, -10:]\n",
    "    \n",
    "    # index into the classes list using the top ten indices to get the class names\n",
    "    top10_preds = estimator.classes_[top10_idx]\n",
    "\n",
    "    # check if y-true is in top 10 for each set of predictions\n",
    "    mask = top10_preds == y.reshape((y.size, 1))\n",
    "    \n",
    "    # take the mean\n",
    "    top_10_accuracy = mask.any(axis=1).mean()\n",
    " \n",
    "    return top_10_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing Features from DNA Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(NOTE:  All text in this section is verbatim from the Benchmark blog posting for this competition)_\n",
    "\n",
    "For this benchmark, we're going to use the DNA sequences as the basis for the features in our model. We've got some preprocessing work to do to turn these lengthy strings into useful features!\n",
    "\n",
    "These sequences are composed of five characters. G, C, A, and T represent the four nucleotides commonly found in DNA (guanine, cytosine, adenine, thymine). N stand for any nucleotide (not a gap).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bases = set(''.join(train_values.sequence.values))\n",
    "bases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One common way to turn strings into useful features is to count n-grams, or continuous subsequences of length n. Here, we'll split up the DNA sequences into four-grams, or subsequences consisting of 4 bases.\n",
    "\n",
    "With 5 unique bases, we can produce 120 different sequence permutations consisting of 4 bases. You can play around with the length of n to see how it affects your model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "subsequences = [''.join(permutation) for permutation in permutations(bases, r=n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of subsequences:  {len(subsequences)}')\n",
    "subsequences[0:120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now turn our strings into features by taking a simple count of each subsequence. We could do this one of two ways:\n",
    "\n",
    "1. Overlapping substrings: To count overlapping substrings, we would use a sliding window such that the sequence \"ATTATTA\" will result in a count of 2 for the substring \"ATTA\" (\"ATTA-TTA\" and \"ATT-ATTA\").\n",
    "\n",
    "2. Non-overlapping substrings: To count non-overlapping substrings, we search for each substring. If we find it, we count it and then continue our search at the end of the substring. In this case, \"ATTATTA\" will result in a count of 1 for the substring \"ATTA\" (\"ATTA-TTA\").\n",
    "\n",
    "For simplicity, we're going to use the second method of non-overlapping substrings. We can use the built in ```count``` method on strings. Feel free to try both methods to see how it affects your model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of built-in count method on strings\n",
    "# Because it's non-overlapping, \"atta\" is only counted twice\n",
    "\"gattattattaca\".count(\"atta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a helper function to generate features.  ```get_ngram_features``` will create a new dataframe that holds the counts for each subsequence and row in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_features(data, subsequences):\n",
    "    \"\"\"Generates counts for each subsequence.\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): The data you want to create features from. Must include a \"sequence\" column.\n",
    "        subsequences (list): A list of subsequences to count.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame with one column for each subsequence.\n",
    "    \"\"\"\n",
    "    features = pd.DataFrame(index=data.index)\n",
    "    for subseq in subsequences:\n",
    "        features[subseq] = data.sequence.str.count(subseq)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our helper function, we can generate features for all the sequences in our training set! This will take a minute or two to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate n-gram features in training data set\n",
    "ngram_features = get_ngram_features(train_values, subsequences)\n",
    "ngram_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have features for all 120 possible subsequences. Their values show the counts of each 4-gram within the full DNA sequence.\n",
    "\n",
    "Let's join them with our one-hot endcoded binary features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = ngram_features.join(train_values.drop('sequence', axis=1))\n",
    "all_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Error Metric:  Top 10 Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NOTE:  All text in this section is verbatim from the Benchmark blog posting for this competition.  The purpose of this blog is to guide participants in the competition through the initial set-up stages of the modeling._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The goal for this competition is to help narrow down the field of possible labs-of-origin from thousands to just a few. To that end, predictions will be evaluated based on top-ten accuracy. That means we'll consider a prediction \"correct\" if the true lab-of-origin is in the top ten most likely labs.\n",
    "\n",
    "There is not a built in evaluation metric for top-k accuracy in scikit-learn, so we'll be constructing a custom scorer. We'll use this to determine the final accuracy of our model.\n",
    "\n",
    "First, we'll need to create a custom scorer that can take in an estimator, validation data, and labels, and output a score based on the top ten results from each predicton. Scikit-learn lets us do this if we adhere to a specific signature.\n",
    "\n",
    "From the scikit-learn documentation:\n",
    "\n",
    "    For a callable to be a scorer, it needs to meet the protocol specified by the following two rules:\n",
    "\n",
    "    It can be called with parameters (estimator, X, y), where estimator is the model that should be evaluated, X is validation data, and y is the ground truth target for X (in the supervised case) or None (in the unsupervised case).\n",
    "\n",
    "    It returns a floating point number that quantifies the estimator prediction quality on X, with reference to y. Again, by convention higher numbers are better, so if your scorer returns loss, that value should be negated.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top10_accuracy_scorer(estimator, X, y):\n",
    "    '''\n",
    "    A custom scorer that evaluates a model on whether the correct label is in \n",
    "    the top 10 most probable predictions.\n",
    "\n",
    "    Args:\n",
    "        estimator (sklearn estimator): The sklearn model that should be evaluated.\n",
    "        X (numpy array): The validation data.\n",
    "        y (numpy array): The ground truth labels.\n",
    "\n",
    "    Returns:\n",
    "        float: Accuracy of the model as defined by the proportion of predictions\n",
    "               in which the correct label was in the top 10. Higher is better.\n",
    "    '''\n",
    "    \n",
    "    # predict the probabilities across all possible labels for rows in our training set\n",
    "    probas = estimator.predict_proba(X)\n",
    "    \n",
    "    # get the indices for top 10 predictions for each row; these are the last ten in each row\n",
    "    \n",
    "    # Note: We use argpartition, which is O(n), vs argsort, which uses the quicksort algorithm \n",
    "    # by default and is O(n^2) in the worst case. We can do this because we only need the top ten\n",
    "    # partitioned, not in sorted order.\n",
    "    # Documentation: https://numpy.org/doc/1.18/reference/generated/numpy.argpartition.html\n",
    "    top10_idx = np.argpartition(probas, -10, axis=1)[:, -10:]\n",
    "    \n",
    "    # index into the classes list using the top ten indices to get the class names\n",
    "    top10_preds = estimator.classes_[top10_idx]\n",
    "\n",
    "    # check if y-true is in top 10 for each set of predictions\n",
    "    mask = top10_preds == y.reshape((y.size, 1))\n",
    "    \n",
    "    # take the mean\n",
    "    top_10_accuracy = mask.any(axis=1).mean()\n",
    " \n",
    "    return top_10_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(From the blog):_\n",
    "Random forests are often a good first model to try so we'll start there. We'll leave more complicated modeling and feature selection up to you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easy to build a random forest model with Scikit Learn. We're going to create a simple model with a few specified hyperparameters.\n",
    "\n",
    "Tip: If you wanted to get fancy, you could perform a cross-validated grid search with ```GridSearchCV```. You could even use the custom scorer we made earlier to train your model by passing it in via the ```scoring``` parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate labels and rename features to match\n",
    "\n",
    "# Rename features to X\n",
    "X = all_features\n",
    "\n",
    "# Create labels\n",
    "y = lab_ids.values.ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got our features and our labels. Time to train!\n",
    "\n",
    "Wait a sec... aren't we forgetting something? Oh right, we still have to address the class imbalance we discovered earlier. Luckily, scikit-learn has an easy solution for us. We can set ```class_weight``` to \"balanced\". This will set class weights inversely proportional to the class frequency.\n",
    "\n",
    "Great! Now let's generate and fit our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate RF model\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=4, n_estimators=150, class_weight='balanced', max_depth=3, random_state=0)\n",
    "\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the top 10 scorer, we should expect to do better on the competition metric, top-10 accuracy. Let's use our custom defined scorer to see how we did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_accuracy_scorer(rf, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model got almost 40% top-ten accuracy.  With this new model, let's make some predictions and see how we do.  \n",
    "\n",
    "We'll create features from our test set and generate predictions. We need to make sure to generate probabilities for each lab ID so that the top 10 accuracy metric can be computed.\n",
    "\n",
    "First, let's create the 4-gram features and join it with the binary features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ngram_features = get_ngram_features(test_values, subsequences)\n",
    "all_test_features = test_ngram_features.join(test_values.drop('sequence', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions\n",
    "\n",
    "It's important to use ```predict_proba``` here, which gives us class probabilities, instead of ```predict```, which would give us class predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = rf.predict_proba(all_test_features)\n",
    "\n",
    "probas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probas[0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the indices for top 10 predictions for each row; these are the last ten in each row\n",
    "\n",
    "# Note: We use argpartition, which is O(n), vs argsort, which uses the quicksort algorithm \n",
    "# by default and is O(n^2) in the worst case. We can do this because we only need the top ten\n",
    "# partitioned, not in sorted order.\n",
    "# Documentation: https://numpy.org/doc/1.18/reference/generated/numpy.argpartition.html\n",
    "\n",
    "top10_idx = np.argpartition(probas, -10, axis=1)[:, -10:]\n",
    "top10_idx[1000:1010]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(top10_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index into the classes list using the top ten indices to get the class names\n",
    "top10_preds = rf.classes_[top10_idx]\n",
    "\n",
    "# # check if y-true is in top 10 for each set of predictions\n",
    "# mask = top10_preds == y.reshape((y.size, 1))\n",
    "\n",
    "# # take the mean\n",
    "# top_10_accuracy = mask.any(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(top10_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top10_preds[0][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.reshape((y.size, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase II: Building on DrivenData Blog Guidance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values.loc[['9ZIMC'], ['sequence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_values.loc[['9ZIMC'], ['sequence']].values.tolist()    # displays entire sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = train_values.columns.tolist()\n",
    "col_list.pop(0)\n",
    "col_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running baseline model before creating features from DNA sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_values.drop(['sequence'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reusing y from above\n",
    "y[:30]\n",
    "# displaying first 30 to make sure content is as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate RF model\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=4, n_estimators=150, class_weight='balanced', max_depth=3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the top 10 scorer, we should expect to do better on the competition metric, top-10 accuracy. Let's use our custom defined scorer to see how we did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_accuracy_scorer(rf, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first score (0.1144770 == 11.4%) in the baseline model represents the accuracy of the model picking one of the 1314 labs in the database.  This is better than the likelihood that randomly selecting one lab out of 1314 and having that selection be correct.  However, if you were to put weights on each lab corresponding to the fraction of all plasmids that each lab contributes to the database, then you would be better off just picking lab 'I7FXTVDP' every time, because that lab contributed over 13% of all plasmids to the database.  \n",
    "\n",
    "The top 10 probabilities accuracy score represents how often the correct label (lab) was included in the model's top 10 highest lab probabilities for a particular plasmid.  On average, the correct lab was in the top 10 predictions for each plasmid over 31% of the time.  This is certainly better than the probability that the correct lab happened to be represented by 10 random lab id draws for each plasmid (approximately 1 in 131, or 0.76%).  However, the top 10 labs contribute just over 30% of all plasmids to the database, so the baseline model is again not much better than just picking the top 10 labs every time.  \n",
    "\n",
    "Obviously, other modeling approaches are necessary to improve upon this baseline.  Below, I explore two different feature selection approaches for use in a random forest or similar ensemble method:  1) 3n-grams, and 2) providing a small subset of sequences known to be used in the engineering of plasmids for cloning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering and Model Run:  3 bp Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating all possible 3-letter sequence combinations for A, T, G, C, and N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating 3-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "subseqs_3bp = [''.join(combination) for combination in product(bases, repeat=n)]\n",
    "\n",
    "print(f'Number of subsequences:  {len(subseqs_3bp)}')\n",
    "subseqs_3bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate n-gram features in training data set\n",
    "ngram_features = get_ngram_features(train_values, subseqs_3bp)\n",
    "ngram_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = ngram_features.join(train_values.drop('sequence', axis=1))\n",
    "all_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model on 3-letter DNA sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate labels and rename features to match\n",
    "\n",
    "# Rename features to X\n",
    "X = all_features\n",
    "\n",
    "# Create labels\n",
    "y = lab_ids.values.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate RF model\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=4, n_estimators=150, class_weight='balanced', max_depth=3, random_state=0)\n",
    "\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the top 10 scorer, we should expect to do better on the competition metric, top-10 accuracy. Let's use our custom defined scorer to see how we did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_accuracy_scorer(rf, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering and Model Run:  Commonly Used Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional sequences include repeats, common restriction enzyme recognition sites, origins of replication, primers, start and stop codons, and more.  I selected a sampling of very commonly used sequences as a starting point to run a basic model and see whether performance improved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional sequences (e.g., RE recognition sites, ORIs, primers, and more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subseqs_4bp_repeats = ['AAAA', 'TTTT', 'GGGG', 'CCCC', 'NNNN']\n",
    "subseqs_4bp_repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE_subseqs_dict = {'Aaal': 'CGGCCG', 'Aagl': 'GAATTC', 'AatII': 'gacgtca'.upper(), 'AclI': 'AACGTT', \n",
    "                   'AhdI': 'gacggtgcgtc'.upper(), \n",
    "                   'Alul': 'AGCT', 'BalI': 'TGGCCA', 'BamHI': 'GGATCC', 'BpmI': 'CTGGAGNNNNNNNNNNNNNNNN',\n",
    "                   'Bpu10I': 'agctaagg'.upper(), \n",
    "                   'BsmI': 'GAATGCN', 'BspEI': 'TCCGGA', 'BsrDI': 'gcaatgnn'.upper(), 'BtgZI': 'GCGATCNNNNNNNNNN', \n",
    "                   'DrdI': 'gactgcagggtc'.upper(), 'EagI': 'cggccg'.upper(), \n",
    "                   'EcoRI': 'GAATTC', 'EcoRV': 'GATATC', 'HaeIII': 'GGCC', 'HindIII':'AAGCTT', 'KpnI': 'GGTACC',  \n",
    "                   'MscI': 'TGGCCA',\n",
    "                   'NdeI': 'gcatat'.upper(), 'Not1': 'GCGGCCGC', 'PaeR7I': 'ctcgag'.upper(), 'PflMI': 'CCANNNNNTTG', \n",
    "                   'PovII': 'CAGCTG', \n",
    "                   'PstI': 'CTGCAG', 'PvuII': 'CAGCTG', \n",
    "                   'SacI': 'GTCGAC', 'SalI': 'GTCGAC', \n",
    "                   'Sau3A': 'GATC', 'SmaI': 'CCCGGG', 'SphI': 'gcatgc'.upper(), 'SstI': 'GAGCTC', \n",
    "                   'TaqI': 'TCGA', 'TaqII': 'GACCGANNNNNNNNNNN', 'XhoI': 'ctcgag'.upper(), \n",
    "                   'XmaI': 'CCCGGG', 'ZraI': 'gacgtc'.upper()}\n",
    "RE_subseqs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE_recog_seqs = list(RE_subseqs_dict.values())\n",
    "RE_recog_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(RE_recog_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most common start codon is ATG\n",
    "start_codon = ['ATG']\n",
    "start_codon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_codons = ['TAG', 'TAA', 'TGA']\n",
    "stop_codons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primer_seqs_ori = {'L4440': 'AGCGAGTCAGTGAGCGAG', 'pBR322ori-F': 'GGGAAACGCCTGGTATCTTT', 'CAT-R': 'GCAACTGACTGAAATGCCTC'}\n",
    "primer_seqs_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primer_seqs = list(primer_seqs_ori.values())\n",
    "primer_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "his_oper_term = ['tcttttcggttttaaagaaaaagggcagggtggtgacaccttgcccttttttgccgga'.upper()]\n",
    "his_oper_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biobrick = ['cctctagaagcggccgcgaattc'.upper()]\n",
    "biobrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Col_E2 = ['CCGCAGCCGAACGACCGAGC']\n",
    "Col_E2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_add_seq_list = subseqs_4bp_repeats + RE_recog_seqs + start_codon + stop_codons + \\\n",
    "                        primer_seqs + his_oper_term + biobrick + Col_E2\n",
    "combined_add_seq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combined_add_seq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(combined_add_seq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(combined_add_seq_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_seqs_ngram_features = get_ngram_features(train_values, combined_add_seq_list)\n",
    "add_seqs_ngram_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_seqs_ngram_features.shape\n",
    "\n",
    "# Note that more than one restriction endonuclease can recognize a given 5' DNA sequence; the list of RE's above \n",
    "# does contain some repetitions.  The set contains 47 unique DNA sequences.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_sel_seqs = add_seqs_ngram_features.join(train_values.drop('sequence', axis=1))\n",
    "all_features_sel_seqs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_sel_seqs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model on selected DNA sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate labels and rename features to match\n",
    "\n",
    "# Rename features to X\n",
    "X_rf = all_features_sel_seqs\n",
    "\n",
    "# Create labels\n",
    "y_rf = lab_ids.values.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate RF model\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=4, n_estimators=150, class_weight='balanced', max_depth=3, random_state=0)\n",
    "\n",
    "rf.fit(X_rf, y_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_rf, y_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_accuracy_scorer(rf, X_rf, y_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion from running Random Forest models on these features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with Random Forests (which is what the Benchmark blog did on an initial set of engineered features), the best results for top-10 probabilities were achieved using a set of DNA sequences corresponding to some important elements of plasmids.  These include common start and stop codons, two base-pair repeats, commonly used restriction enzyme recognition sites, and a few other recognition sequences (e.g., primers, origin of replication, open reading frame) for a start.  This list of sequences is just scratching the surface of all of the potential sequences used in DNA plasmid replication, but represents some of the most commonly used recognition sites on plasmids.\n",
    "\n",
    "The random forest approach is not likely to give the best results, given the importance of letter order in making sense of DNA sequences and the fact that random forest models do not factor in letter order.  My feeling is that more sophisticated modeling approaches such as neural networks are likely to be more productive.  With that, I will turn my attention to some of these approaches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase III:  Exploring Neural Networks (NNs) as a Modeling Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thought process when considering which neural network(s) to set up for this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In thinking about the features of plasmids that could point towards their labs-of-origin, I realized that DNA sequences share some characteristics with language, and other characteristics with images.  As neural networks are well-suited to finding features, identifying patterns across spatial dimensions, and the integrating these features into a whole in a meaningful way, I knew that this would be my next step for this project.\n",
    "\n",
    "Let's explore how finding functional significance in DNA sequences compare to both language processing and image processing/recognition:\n",
    "\n",
    "### How are DNA sequences similar to languages?  \n",
    "I can think of at least two ways:\n",
    "* Languages and DNA both use combinations of “letters” in a linear fashion to encode information and convey meaning\n",
    "* Furthermore, the combination of words and sequences in a document or plasmid convey information about the author (writing style in the case of language, sequence presence and location for plasmids)\n",
    "\n",
    "### How are DNA sequences similar to images?  \n",
    "* Images and DNA sequences are similar in that the locations of a sequences relative to each other share some similarities with the local features in images that a neural network analyzes, finding patterns across local features and tying these together into a larger whole\n",
    "* DNA sequences can range from extremely short (e.g., just a handful of base pairs, thus essentially a very small localized feature) to very long (e.g., thousands of letters, which can be viewed as a larger feature that stretches across a significant portion of an image)\n",
    "\n",
    "***There are also some important differences between language structure and DNA structure:***\n",
    "* DNA doesn’t have clear ‘punctuation’ and spaces the way languages do to clearly denote specific words or phrases, so it can be difficult to tell where important information begins and ends\n",
    "* Further, letter substitution (sometimes for multiple base pairs in a row) can occur in certain kinds of DNA sequences, creating a combinatorial headache in which even relatively short sequences of 20-30 base pairs can go from essentially being one ‘word’ to being many acceptable variations of a word\n",
    "\n",
    "To the extent that DNA sequences share characteristics with language, a neural network such as a Recurrent Neural Network (RNN) with LSTM or GRU layers could provide beneficial.  On the other hand, the similarities to some aspects of image processing suggest a convolutional neural network (CNN).  \n",
    "\n",
    "Because of these differences between language and DNA sequences, I figured that some of the tools used for NLP might not work as well in identifying lab-of-origin from plasmid sequences.  I also figured that tools used for image analysis and recognition can do a better job because they can find relationships and structure at a more localized granular level and scale this information up to a meaningful whole.  Thus, I decided to proceed first with the CNN and potentially explore RNNs and other approaches if time allowed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Dense\n",
    "# from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before setting up a full-scale model, I'm going to reduce the number of sequences and labs that are contained in the dataset.  The purpose of this is to be able to successfully run a smaller-scale model and make decisions about what needs to be adjusted before introducing more data into the model.  \n",
    "\n",
    "Reviewing the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting lab IDs in a vertical format, rather than as column headers\n",
    "lab_ids = pd.DataFrame(train_labels.idxmax(axis=1), columns=['lab_id'])\n",
    "lab_ids.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reducing dataframe size to increase the speed of training models\n",
    "\n",
    "Given the amount of time neural network models require to run, I will first reduce the number of data points in the data set.  To start, I will select only those plasmids contributed by labs that are more frequent contributors to the database.  This will provide a foundation on which to further explore modeling approaches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values_df = train_values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values_df['seq_len'] = train_values_df.sequence.apply(len)\n",
    "train_values_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding seq length and lab_id columns to train_values df, to allow selection of subset of plasmids (number of plasmids per lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values_labels = pd.concat([train_values_df, lab_ids], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting the minimum number of plasmids that a lab must contribute for that lab (and its associated plasmids) to be included in the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My first effort at reducing the dataset size was to limit the labs to those contributing at least 50 plasmids to the database.  However, even with this relatively large number, there were still over 45000 data points in the data set and 213 labs.  \n",
    "\n",
    "Since some labs have contributed over 1000 plasmids to the database, and many labs have contributed several hundred, I will select a higher minimum value of plasmids per lab as a threshold for inclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_df_size(df, num_plasmid):\n",
    "    '''\n",
    "    Takes df with all values and targets and returns the following 3 items that only \n",
    "    contain data points corresponding to labs and sequences from labs contributing \n",
    "    the top X number of plasmids:  1) complete dataframe with all binary variables, \n",
    "    sequences, and labels; 2) dataframe with just the sequence (index is sequence ID); \n",
    "    and 3) dataframe with just the lab ID (index is sequence ID).\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    \n",
    "    labs_grouped = df.groupby(['lab_id']).count().sort_values(by='sequence', \n",
    "                                                              ascending=False)    \n",
    "    labs_grpd_num_plasmid = labs_grouped.loc[labs_grouped['sequence'] >= num_plasmid]\n",
    "    labs_grpd_num_plasmid = labs_grpd_num_plasmid.reset_index()\n",
    "    df_subset_list = labs_grpd_num_plasmid.lab_id.tolist()\n",
    "    df_subset = df.loc[df['lab_id'].isin(df_subset_list)]\n",
    "    print(f\"There are {len(df_subset_list)} labs in this subset dataframe\")\n",
    "    print(f\"Each lab has submitted at least {num_plasmid} plasmids\")\n",
    "    df_subset_labs_seqs = df_subset[['sequence', 'seq_len', 'lab_id']]\n",
    "    train_seqs_subset = df_subset_labs_seqs.drop(['seq_len','lab_id'], axis=1)\n",
    "    train_labs_subset = df_subset_labs_seqs.drop(['sequence', 'seq_len'], axis=1)\n",
    "    return df_subset_labs_seqs, train_seqs_subset, train_labs_subset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset_200, seqs_subset_200, labs_subset_200 = reduce_df_size(train_values_labels, num_plasmid=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_subset_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_subset_200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have our reduced-size dataframe, which is limited to plasmids that have been submitted by labs that have submitted at least 200 plasmids to the AddGene database (42 labs in total).  We also have separate dataframes for sequences and labs.\n",
    "\n",
    "Looking at the frequences of lab IDs associated with plasmids, we see that the top-contributing lab represents almost 28% of all contributions in this group of plasmids.  The top 10 labs contribute ~65% of the plasmids in this dataset--meaning the 32 remaining labs contribute the remaining 35% of plasmids in this subset of plasmids from labs contributing at least 200 plasmids to the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_subset_200.value_counts(normalize=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Character-level vectorization:  values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in preparing the data for analysis in the CNN is to tokenize the base pair letters in the sequences and the lab IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_subset_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seqs_subset_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_subset_200.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(seqs_subset_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_200 = seqs_subset_200.sequence.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(seqs_200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(lower = False, char_level = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(seqs_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_200 = tokenizer.texts_to_sequences(seqs_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_200[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Padding sequences to max_char length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_char = 8500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_200_85 = sequence.pad_sequences(X_200, maxlen=max_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_200_85.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_200_85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_200_85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=None)\n",
    "\n",
    "X_200_85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that the information is properly encoded, we can get the dictionary of tokens with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Found {} unique tokens'.format(len(word_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lab ID vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_subset_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ids_200 = labs_subset_200.lab_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ids_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_lab = Tokenizer(lower = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_lab.fit_on_texts(lab_ids_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_200 = tokenizer_lab.texts_to_sequences(lab_ids_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_200 = np.array(Y_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Transform labels to one-hot\n",
    "lb = LabelBinarizer()\n",
    "y_200 = lb.fit_transform(Y_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_200[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_200.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_inv_200 = lb.inverse_transform(y_200)\n",
    "y_inv_200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_test_split on this data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_200_85, X_test_200_85, y_train_200_85, y_test_200_85 = train_test_split(X_200_85, y_200, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_200_85.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_200_85.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_200_85.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_200_85.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_inv_200_85 = lb.inverse_transform(y_train_200_85)\n",
    "y_train_inv_200_85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute class weights for training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create class weights for tokenized training data subset\n",
    "\n",
    "from sklearn import utils \n",
    "\n",
    "def class_weights_dict_tokenized(y):\n",
    "    \n",
    "    '''Function to create class weights for a subset of tokenized training labels'''\n",
    "       \n",
    "    # create unique class array from y\n",
    "    classes = np.unique(y)\n",
    "    \n",
    "    # Compute class weights using sklearn module\n",
    "    class_weights = utils.compute_class_weight('balanced', classes, y = np.ravel(y))\n",
    "#     class_list = classes.tolist()\n",
    "#     class_weights_list = class_weights.tolist()\n",
    "#     class_wts_dict = dict(zip(class_list, class_weights_list))\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weights_dict_tokenized(Y_200)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D CNN Models using data subset of sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model:  labs submitting at least 200 plasmids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_char = 8500\n",
    "\n",
    "model = Sequential()\n",
    "embedding_dim = 1\n",
    "model.add(Embedding(len(word_index) + 1, embedding_dim, input_length=max_char))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"input shape: \", model.input_shape)\n",
    "print(\"output shape: \", model.output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Conv1D(filters=32, kernel_size=12, padding='same', activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"output shape: \", model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.AveragePooling1D(pool_size=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"output shape: \", model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Conv1D(filters=32, kernel_size=8, padding='same', activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"output shape: \", model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.AveragePooling1D(pool_size=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"output shape: \", model.output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"output shape: \", model.output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(64, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"output shape: \", model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(len(y_train_200_85[0]), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"output shape: \", model.output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "\n",
    "# Model: \"sequential\"\n",
    "# _________________________________________________________________\n",
    "# Layer (type)                 Output Shape              Param #   \n",
    "# =================================================================\n",
    "# embedding (Embedding)        (None, 8500, 1)           6         \n",
    "# _________________________________________________________________\n",
    "# conv1d (Conv1D)              (None, 8500, 32)          416       \n",
    "# _________________________________________________________________\n",
    "# average_pooling1d (AveragePo (None, 4250, 32)          0         \n",
    "# _________________________________________________________________\n",
    "# conv1d_1 (Conv1D)            (None, 4250, 32)          8224      \n",
    "# _________________________________________________________________\n",
    "# average_pooling1d_1 (Average (None, 2125, 32)          0         \n",
    "# _________________________________________________________________\n",
    "# flatten (Flatten)            (None, 68000)             0         \n",
    "# _________________________________________________________________\n",
    "# dense (Dense)                (None, 64)                4352064   \n",
    "# _________________________________________________________________\n",
    "# dense_1 (Dense)              (None, 42)                2730      \n",
    "# =================================================================\n",
    "# Total params: 4,363,440\n",
    "# Trainable params: 4,363,440\n",
    "# Non-trainable params: 0\n",
    "# _________________________________________________________________\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit(X_train_200_85, y_train_200_85, epochs=12, validation_data=(X_test_200_85, y_test_200_85), class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for visualizing training/validation loss and training/validation accuracy\n",
    "\n",
    "def loss_viz(model, figsize=(10, 5)):\n",
    "    history = model.history\n",
    "    train_loss_vals = history[\"loss\"]\n",
    "    validation_loss_vals = history[\"val_loss\"]\n",
    "    \n",
    "    epochs = range(1, len(train_loss_vals) + 1)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(epochs, train_loss_vals, 'b', label='Training Loss')\n",
    "    plt.plot(epochs, validation_loss_vals, 'r', label='Validation Loss')\n",
    "    \n",
    "    plt.title('Training and Validation Losses')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def acc_viz(model, figsize=(10, 5)):\n",
    "    history = model.history\n",
    "    train_acc = history[\"accuracy\"]\n",
    "    val_acc = history[\"val_accuracy\"]\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    epochs = range(1, len(train_acc) + 1)\n",
    "    plt.plot(epochs, train_acc, 'b', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "    \n",
    "    plt.title('Training vs. Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_viz(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_viz(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(10, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 3) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations about model\n",
    "\n",
    "(placeholder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_a:  labs submitting at least 200 plasmids--changing number of filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model setup:  changing from 32 filters to 64 filters; kernel size same, still 8500 max characters per plasmid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_char = 8500\n",
    "\n",
    "model_a = Sequential()\n",
    "\n",
    "embedding_dim = 1\n",
    "model_a.add(Embedding(len(word_index) + 1, embedding_dim, input_length=max_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a.add(layers.Conv1D(filters=64, kernel_size=12, padding='same', activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a.add(layers.AvgPool1D(pool_size=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a.add(layers.Conv1D(filters=32, kernel_size=8, padding='same', activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a.add(layers.AveragePooling1D(pool_size=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a.add(layers.Flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a.add(layers.Dense(64, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a.add(layers.Dense(len(y_train_200_85[0]), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a.summary()\n",
    "\n",
    "# Model: \"sequential_3\"\n",
    "# _________________________________________________________________\n",
    "# Layer (type)                 Output Shape              Param #   \n",
    "# =================================================================\n",
    "# embedding_3 (Embedding)      (None, 8500, 1)           6         \n",
    "# _________________________________________________________________\n",
    "# conv1d_6 (Conv1D)            (None, 8500, 64)          832       \n",
    "# _________________________________________________________________\n",
    "# average_pooling1d_6 (Average (None, 4250, 64)          0         \n",
    "# _________________________________________________________________\n",
    "# conv1d_7 (Conv1D)            (None, 4250, 32)          16416     \n",
    "# _________________________________________________________________\n",
    "# average_pooling1d_7 (Average (None, 2125, 32)          0         \n",
    "# _________________________________________________________________\n",
    "# flatten_3 (Flatten)          (None, 68000)             0         \n",
    "# _________________________________________________________________\n",
    "# dense_6 (Dense)              (None, 64)                4352064   \n",
    "# _________________________________________________________________\n",
    "# dense_7 (Dense)              (None, 42)                2730      \n",
    "# =================================================================\n",
    "# Total params: 4,372,048\n",
    "# Trainable params: 4,372,048\n",
    "# Non-trainable params: 0\n",
    "# _________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "history_a = model_a.fit(X_train_200_85, y_train_200_85, epochs=12, validation_data=(X_test_200_85, y_test_200_85), class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_a.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_a.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_viz(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_viz(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(10, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 3) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a.save('my_model_a.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations about model\n",
    "\n",
    "The change in number of filters made virtually no difference in the validation accuracy.  The training accuracy, however, was slightly higher in model_a (64 filters vs. 32 used in the first model).  The slightly greater spread from training to validation accuracy in model_a vs. model suggests overfitting, since the validation accuracies were virtually identical.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_1:  labs submitting at least 200 plasmids each--changing pooling layers; adding dropout layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An earlier run of this model swapping out Average Pooling 1D layers for MaxPooling 1D layers, with either filter = 32 or filter = 64, gave somewhat better results than the first two models above.  Further, earlier modeling efforts showed that models with dropout layers generally performed better than those without.  Therefore, I'm going to add two dropout layers along with the swap to MaxPooling1D layers.  I'm also changing the filter number back to 32, to help reduce computational complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model setup--switching to MaxPooling1D; adding dropout layers; still 8500 characters max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_char = 8500\n",
    "\n",
    "model_1 = Sequential()\n",
    "embedding_dim = 1\n",
    "model_1.add(Embedding(len(word_index) + 1, embedding_dim, input_length=max_char))\n",
    "model_1.add(layers.Conv1D(filters=32, kernel_size=12, padding='same', activation='relu'))\n",
    "model_1.add(layers.MaxPooling1D(pool_size=2))\n",
    "model_1.add(Dropout(0.2))\n",
    "model_1.add(layers.Conv1D(filters=32, kernel_size=8, padding='same', activation='relu'))\n",
    "model_1.add(layers.MaxPooling1D(pool_size=2))\n",
    "model_1.add(Dropout(0.2))\n",
    "model_1.add(layers.Flatten())\n",
    "model_1.add(layers.Dense(64, activation='relu'))\n",
    "model_1.add(layers.Dense(len(y_train_200_85[0]), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_1.summary())\n",
    "\n",
    "# Model: \"sequential_11\"\n",
    "# _________________________________________________________________\n",
    "# Layer (type)                 Output Shape              Param #   \n",
    "# =================================================================\n",
    "# embedding_11 (Embedding)     (None, 10000, 1)          6         \n",
    "# _________________________________________________________________\n",
    "# conv1d_22 (Conv1D)           (None, 10000, 32)         416       \n",
    "# _________________________________________________________________\n",
    "# max_pooling1d_14 (MaxPooling (None, 5000, 32)          0         \n",
    "# _________________________________________________________________\n",
    "# dropout_6 (Dropout)          (None, 5000, 32)          0         \n",
    "# _________________________________________________________________\n",
    "# conv1d_23 (Conv1D)           (None, 5000, 32)          8224      \n",
    "# _________________________________________________________________\n",
    "# max_pooling1d_15 (MaxPooling (None, 2500, 32)          0         \n",
    "# _________________________________________________________________\n",
    "# dropout_7 (Dropout)          (None, 2500, 32)          0         \n",
    "# _________________________________________________________________\n",
    "# flatten_11 (Flatten)         (None, 80000)             0         \n",
    "# _________________________________________________________________\n",
    "# dense_22 (Dense)             (None, 64)                5120064   \n",
    "# _________________________________________________________________\n",
    "# dense_23 (Dense)             (None, 42)                2730      \n",
    "# =================================================================\n",
    "# Total params: 5,131,440\n",
    "# Trainable params: 5,131,440\n",
    "# Non-trainable params: 0\n",
    "# _________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "history_1 = model_1.fit(X_train_200_85, y_train_200_85, epochs=12, validation_data=(X_test_200_85, y_test_200_85), class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1.params\n",
    "\n",
    "# {'verbose': 1, 'epochs': 10, 'steps': 699}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_viz(history_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_viz(history_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_1.history).plot(figsize=(10, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 3) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save('my_model_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations about model\n",
    "\n",
    "(placeholder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_1b:  labs submitting at least 200 plasmids each--changing Dense layer connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model setup--changing 1st Dense layer from 64 to 128; still 8500 characters max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_char = 8500\n",
    "\n",
    "model_1b = Sequential()\n",
    "embedding_dim = 1\n",
    "model_1b.add(Embedding(len(word_index) + 1, embedding_dim, input_length=max_char))\n",
    "model_1b.add(layers.Conv1D(filters=32, kernel_size=12, padding='same', activation='relu'))\n",
    "model_1b.add(layers.MaxPooling1D(pool_size=2))\n",
    "model_1b.add(Dropout(0.2))\n",
    "model_1b.add(layers.Conv1D(filters=32, kernel_size=8, padding='same', activation='relu'))\n",
    "model_1b.add(layers.MaxPooling1D(pool_size=2))\n",
    "model_1b.add(Dropout(0.2))\n",
    "model_1b.add(layers.Flatten())\n",
    "model_1b.add(layers.Dense(128, activation='relu'))\n",
    "model_1b.add(layers.Dense(len(y_train_200_85[0]), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_1b.summary())\n",
    "\n",
    "# Model: \"sequential_7\"\n",
    "# _________________________________________________________________\n",
    "# Layer (type)                 Output Shape              Param #   \n",
    "# =================================================================\n",
    "# embedding_7 (Embedding)      (None, 8500, 1)           6         \n",
    "# _________________________________________________________________\n",
    "# conv1d_14 (Conv1D)           (None, 8500, 64)          832       \n",
    "# _________________________________________________________________\n",
    "# max_pooling1d_6 (MaxPooling1 (None, 4250, 64)          0         \n",
    "# _________________________________________________________________\n",
    "# conv1d_15 (Conv1D)           (None, 4250, 32)          16416     \n",
    "# _________________________________________________________________\n",
    "# max_pooling1d_7 (MaxPooling1 (None, 2125, 32)          0         \n",
    "# _________________________________________________________________\n",
    "# flatten_7 (Flatten)          (None, 68000)             0         \n",
    "# _________________________________________________________________\n",
    "# dense_14 (Dense)             (None, 128)               8704128   \n",
    "# _________________________________________________________________\n",
    "# dense_15 (Dense)             (None, 42)                5418      \n",
    "# =================================================================\n",
    "# Total params: 8,726,800\n",
    "# Trainable params: 8,726,800\n",
    "# Non-trainable params: 0\n",
    "# _________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1b.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "history_1b = model_1b.fit(X_train_200_85, y_train_200_85, epochs=12, validation_data=(X_test_200_85, y_test_200_85), class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1b.history['accuracy']\n",
    "\n",
    "# [0.4287184774875641,\n",
    "#  0.650015652179718,\n",
    "#  0.7707801461219788,\n",
    "#  0.8564969897270203,\n",
    "#  0.9109708666801453,\n",
    "#  0.9307103157043457,\n",
    "#  0.9564030170440674,\n",
    "#  0.9708607196807861,\n",
    "#  0.9748892188072205,\n",
    "#  0.9900183081626892,\n",
    "#  0.9910925626754761,\n",
    "#  0.9859898686408997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1b.history['val_accuracy']\n",
    "\n",
    "# [0.5182599425315857,\n",
    "#  0.6267454624176025,\n",
    "#  0.6486304998397827,\n",
    "#  0.6895810961723328,\n",
    "#  0.7208646535873413,\n",
    "#  0.7387218475341797,\n",
    "#  0.74221271276474,\n",
    "#  0.7345596551895142,\n",
    "#  0.742078423500061,\n",
    "#  0.7371106743812561,\n",
    "#  0.7254296541213989,\n",
    "#  0.739661693572998]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1b.params\n",
    "\n",
    "# {'verbose': 1, 'epochs': 10, 'steps': 699}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_viz(history_1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_viz(history_1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1b.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_1b.history).plot(figsize=(10, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 3) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1b.save('my_model_1b.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations about model\n",
    "\n",
    "(placeholder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_1c:  Increasing max_char to 10000 and adding dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the reduced size dataframe of sequences that we start with:\n",
    "seqs_subset_200.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seqs_200 = seqs_subset_200.sequence.values   # Code to convert subsequences df into form that can be tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seqs_200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Character-level vectorization:  values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment lines below if seqs_200 requires tokenizing (i.e., if the data preprocessing steps at the beginning of the \"CNN model setup\" section have not been run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = Tokenizer(lower = False, char_level = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.fit_on_texts(seqs_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_200 = tokenizer.texts_to_sequences(seqs_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Padding sequences to max_char length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_char = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_200_10k = sequence.pad_sequences(X_200, maxlen=max_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_200_10k.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_200_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_200_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=None)\n",
    "\n",
    "X_200_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_200_10k.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that the information is properly encoded, we can get the dictionary of tokens with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Found {} unique tokens'.format(len(word_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_200_10k, X_test_200_10k, y_train_200_10k, y_test_200_10k = train_test_split(X_200_10k, y_200, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_200_10k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_200_10k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_200_10k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_200_10k.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model_1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1c = Sequential()\n",
    "embedding_dim = 1\n",
    "model_1c.add(Embedding(len(word_index) + 1, embedding_dim, input_length=max_char))\n",
    "model_1c.add(layers.Conv1D(filters=32, kernel_size=12, padding='same', activation='relu'))\n",
    "model_1c.add(layers.MaxPooling1D(pool_size=2))\n",
    "model_1c.add(Dropout(0.2))\n",
    "model_1c.add(layers.Conv1D(filters=32, kernel_size=8, padding='same', activation='relu'))\n",
    "model_1c.add(layers.MaxPooling1D(pool_size=2))\n",
    "model_1c.add(Dropout(0.2))\n",
    "model_1c.add(layers.Flatten())\n",
    "model_1c.add(layers.Dense(128, activation='relu'))\n",
    "model_1c.add(layers.Dense(len(y_train_200_10k[0]), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_1c.summary())\n",
    "\n",
    "# Model: \"sequential_8\"\n",
    "# _________________________________________________________________\n",
    "# Layer (type)                 Output Shape              Param #   \n",
    "# =================================================================\n",
    "# embedding_8 (Embedding)      (None, 10000, 1)          6         \n",
    "# _________________________________________________________________\n",
    "# conv1d_16 (Conv1D)           (None, 10000, 64)         832       \n",
    "# _________________________________________________________________\n",
    "# max_pooling1d_8 (MaxPooling1 (None, 5000, 64)          0         \n",
    "# _________________________________________________________________\n",
    "# dropout (Dropout)            (None, 5000, 64)          0         \n",
    "# _________________________________________________________________\n",
    "# conv1d_17 (Conv1D)           (None, 5000, 32)          16416     \n",
    "# _________________________________________________________________\n",
    "# max_pooling1d_9 (MaxPooling1 (None, 2500, 32)          0         \n",
    "# _________________________________________________________________\n",
    "# dropout_1 (Dropout)          (None, 2500, 32)          0         \n",
    "# _________________________________________________________________\n",
    "# flatten_8 (Flatten)          (None, 80000)             0         \n",
    "# _________________________________________________________________\n",
    "# dense_16 (Dense)             (None, 128)               10240128  \n",
    "# _________________________________________________________________\n",
    "# dense_17 (Dense)             (None, 42)                5418      \n",
    "# =================================================================\n",
    "# Total params: 10,262,800\n",
    "# Trainable params: 10,262,800\n",
    "# Non-trainable params: 0\n",
    "# _________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1c.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "history_1c = model_1c.fit(X_train_200_10k, y_train_200_10k, epochs=12, validation_data=(X_test_200_10k, y_test_200_10k), class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1c.history['accuracy']\n",
    "\n",
    "# [0.39926591515541077,\n",
    "#  0.6202497482299805,\n",
    "#  0.736896276473999,\n",
    "#  0.804619312286377,\n",
    "#  0.8272682428359985,\n",
    "#  0.8568550944328308,\n",
    "#  0.8832191824913025,\n",
    "#  0.8992435336112976,\n",
    "#  0.9144173860549927,\n",
    "#  0.909001350402832,\n",
    "#  0.9328588247299194,\n",
    "#  0.9377825260162354]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_1c.history['val_accuracy']\n",
    "\n",
    "[0.48885607719421387,\n",
    " 0.5586735010147095,\n",
    " 0.6349355578422546,\n",
    " 0.5676692128181458,\n",
    " 0.649838924407959,\n",
    " 0.690252423286438,\n",
    " 0.6781686544418335,\n",
    " 0.7015306353569031,\n",
    " 0.6973684430122375,\n",
    " 0.6970999240875244,\n",
    " 0.7134801745414734,\n",
    " 0.7024704813957214]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1c.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_viz(history_1c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_viz(history_1c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1c.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_1c.history).plot(figsize=(10, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 5) # set the vertical range to [0-1]\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1c.save('my_model_1c.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations about model_1c\n",
    "\n",
    "In model_1c, I increased the max_char value to 10000 and used a similar structure to model_1b.  Validation accuracy was very similar to model_1b (around 705) but model_1c appears to have less overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations from first runs of Conv1D models\n",
    "The final model in this group (model_1) had the best performance of the first 3 models, with a training accuracy of over 99% and a test accuracy of over 76% in classifying the specific lab that provided the plasmid.  This is significantly better than picking at random, even if you adjust the weights according to lab abundance.\n",
    "* There are 42 labs, so if one were to pick a lab at random for a particular plasmid, the odds of it being correct are 1/42 = 2.4%.  \n",
    "* The top lab provided almost 28% of all plasmids, so if you were to simply guess the most numerous class for each plasmid, you'd be right 28% of the time--substantially less than 75% as provided by the model.  \n",
    "* Even if you look at the top 10 labs, together they contributed 65% of all plasmids to this data sub-set.  \n",
    "* **_Thus, a validation accuracy rate of 76% is substantially better than chance._** \n",
    "\n",
    "Model accuracy improved from \"model\" to \"model_a\", and again from \"model_a\" to \"model_1\".  The changes made were increasing the number of filters from 32 to 64, then changing average pooling layers to max pooling layers.  All other layers were the same from one model to the next.   \n",
    "\n",
    "Interestingly, in the case of the final model, even at the end of 10 epochs, both training and validation accuracy were still increasing, albeit slowly.  We also see a significant drop in validation loss between epoch 9 and 10, which is very different than other models, where val_loss decreasing until only the 3rd or 4th epoch, and then starts increasing again.  Although large validation accuracy improvements are unlikely past this point, it could be informative to see what happens to val_loss and accuracy past epoch 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_2:  labs summitting 50 or fewer plasmids each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting the maximum number of plasmids that a lab has submitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My first effort at reducing the dataset size was to limit the labs to those contributing at least 200 plasmids to the database.  However, even with this relatively large number, there were still over 45000 data points in the data set and 213 labs.  \n",
    "\n",
    "For these runs, I will be focusing on labs submitted fewer than 50 plasmids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_df_size_less_than_max(df, num_plasmid):\n",
    "    '''\n",
    "    Takes df with all values and targets and returns the following 3 items that only \n",
    "    contain data points corresponding to labs and sequences from labs contributing \n",
    "    the top X number of plasmids:  1) complete dataframe with all binary variables, \n",
    "    sequences, and labels; 2) dataframe with just the sequence (index is sequence ID); \n",
    "    and 3) dataframe with just the lab ID (index is sequence ID).\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    \n",
    "    labs_grouped = df.groupby(['lab_id']).count().sort_values(by='sequence', \n",
    "                                                              ascending=True)    \n",
    "    labs_grpd_num_plasmid = labs_grouped.loc[labs_grouped['sequence'] <= num_plasmid]\n",
    "    labs_grpd_num_plasmid = labs_grpd_num_plasmid.reset_index()\n",
    "    df_subset_list = labs_grpd_num_plasmid.lab_id.tolist()\n",
    "    df_subset = df.loc[df['lab_id'].isin(df_subset_list)]\n",
    "    print(f\"There are {len(df_subset_list)} labs in this subset dataframe\")\n",
    "    print(f\"Each lab has submitted no more than {num_plasmid} plasmids\")\n",
    "    df_subset_labs_seqs = df_subset[['sequence', 'seq_len', 'lab_id']]\n",
    "    train_seqs_subset = df_subset_labs_seqs.drop(['seq_len','lab_id'], axis=1)\n",
    "    train_labs_subset = df_subset_labs_seqs.drop(['sequence', 'seq_len'], axis=1)\n",
    "    return df_subset_labs_seqs, train_seqs_subset, train_labs_subset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset_lt_50, seqs_subset_lt_50, labs_subset_lt_50 = reduce_df_size_less_than_max(train_values_labels, num_plasmid=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset_lt_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_subset_lt_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_subset_lt_50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have our reduced-size dataframe, which is limited to plasmids that have been submitted by labs that have submitted less than 50 plasmids to the AddGene database.  We also have separate dataframes for sequences and labs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_subset_lt_50.value_counts(normalize=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Character-level vectorization:  values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in preparing the data for analysis in the CNN is to tokenize the base pair letters in the sequences and the lab IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_subset_lt_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seqs_subset_lt_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_subset_lt_50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(seqs_subset_lt_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_lt_50 = seqs_subset_lt_50.sequence.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_lt_50[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(seqs_lt_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(lower = False, char_level = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(seqs_lt_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lt_50 = tokenizer.texts_to_sequences(seqs_lt_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lt_50[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_lt_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Padding sequences to max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_char = 8500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lt_50_85 = sequence.pad_sequences(X_lt_50, maxlen=max_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lt_50_85.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_lt_50_85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_lt_50_85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lt_50_85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that the information is properly encoded, we can get the dictionary of tokens with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Found {} unique tokens'.format(len(word_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lab ID vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_subset_lt_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ids_lt_50 = labs_subset_lt_50.lab_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ids_lt_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_lab = Tokenizer(lower = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_lab.fit_on_texts(lab_ids_lt_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_lt_50 = tokenizer_lab.texts_to_sequences(lab_ids_lt_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_lt_50 = np.array(Y_lt_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_lt_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Transform labels to one-hot\n",
    "lb = LabelBinarizer()\n",
    "y_lt_50 = lb.fit_transform(Y_lt_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lt_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_lt_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_lt_50[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lt_50.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train_test_split on this data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lt_50, X_test_lt_50, y_train_lt_50, y_test_lt_50 = train_test_split(X_lt_50_85, y_lt_50, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lt_50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_lt_50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_lt_50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_lt_50[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_lt_50.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute class weights for training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create class weights for tokenized training data subset\n",
    "\n",
    "from sklearn import utils \n",
    "\n",
    "def class_weights_dict_tokenized(y):\n",
    "    \n",
    "    '''Function to create class weights for a subset of tokenized training labels'''\n",
    "       \n",
    "    # create unique class array from y\n",
    "    classes = np.unique(y)\n",
    "    \n",
    "    # Compute class weights using sklearn module\n",
    "    class_weights = utils.compute_class_weight('balanced', classes, y = np.ravel(y))\n",
    "#     class_list = classes.tolist()\n",
    "#     class_weights_list = class_weights.tolist()\n",
    "#     class_wts_dict = dict(zip(class_list, class_weights_list))\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_lt_50 = class_weights_dict_tokenized(Y_lt_50)\n",
    "class_weights_lt_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(class_weights_lt_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_char = 8500 \n",
    "model_2 = Sequential()\n",
    "embedding_dim = 1\n",
    "model_2.add(Embedding(len(word_index) + 1, embedding_dim, input_length=max_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.add(layers.Conv1D(filters=32, kernel_size=12, padding='same', activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.add(layers.MaxPooling1D(pool_size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.add(layers.Conv1D(filters=32, kernel_size=8, padding='same', activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.add(layers.MaxPooling1D(pool_size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.add(layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.add(layers.Dense(128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.add(layers.Dense(len(y_train_lt_50[0]), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2 = Sequential()\n",
    "# embedding_dim = 1\n",
    "# model_2.add(Embedding(len(word_index) + 1, embedding_dim, input_length=max_char))\n",
    "# model_2.add(layers.Conv1D(filters=32, kernel_size=12, padding='same', activation='relu'))\n",
    "# model_2.add(layers.MaxPooling1D(pool_size=2))\n",
    "# model_2.add(Dropout(0.2))\n",
    "# model_2.add(layers.Conv1D(filters=32, kernel_size=8, padding='same', activation='relu'))\n",
    "# model_2.add(layers.MaxPooling1D(pool_size=2))\n",
    "# model_2.add(Dropout(0.2))\n",
    "# model_2.add(layers.Flatten())\n",
    "# model_2.add(layers.Dense(128, activation='relu'))\n",
    "# model_2.add(layers.Dense(len(y_train_lt_50[0]), activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.summary()\n",
    "\n",
    "# Model: \"sequential_22\"\n",
    "# _________________________________________________________________\n",
    "# Layer (type)                 Output Shape              Param #   \n",
    "# =================================================================\n",
    "# embedding_22 (Embedding)     (None, 8500, 1)           6         \n",
    "# _________________________________________________________________\n",
    "# conv1d_41 (Conv1D)           (None, 8500, 32)          416       \n",
    "# _________________________________________________________________\n",
    "# max_pooling1d_31 (MaxPooling (None, 4250, 32)          0         \n",
    "# _________________________________________________________________\n",
    "# dropout_22 (Dropout)         (None, 4250, 32)          0         \n",
    "# _________________________________________________________________\n",
    "# conv1d_42 (Conv1D)           (None, 4250, 32)          8224      \n",
    "# _________________________________________________________________\n",
    "# max_pooling1d_32 (MaxPooling (None, 2125, 32)          0         \n",
    "# _________________________________________________________________\n",
    "# dropout_23 (Dropout)         (None, 2125, 32)          0         \n",
    "# _________________________________________________________________\n",
    "# flatten_19 (Flatten)         (None, 68000)             0         \n",
    "# _________________________________________________________________\n",
    "# dense_38 (Dense)             (None, 128)               8704128   \n",
    "# _________________________________________________________________\n",
    "# dense_39 (Dense)             (None, 1106)              142674    \n",
    "# =================================================================\n",
    "# Total params: 8,855,448\n",
    "# Trainable params: 8,855,448\n",
    "# Non-trainable params: 0\n",
    "# _________________________________________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "history_2 = model_2.fit(X_train_lt_50, y_train_lt_50, epochs=12, validation_data=(X_test_lt_50, y_test_lt_50), class_weight = class_weights_lt_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_2.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_2.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_viz(history_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_viz(history_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_2.history).plot(figsize=(10, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 0.1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.save('my_model_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations about model_2\n",
    "\n",
    "(placeholder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_3:  labs submitting 10 or fewer plasmids each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting the maximum number of plasmids that a lab has submitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these runs, I will be focusing on labs submitted fewer than 10 plasmids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_df_size_less_than_max(df, num_plasmid):\n",
    "    '''\n",
    "    Takes df with all values and targets and returns the following 3 items that only \n",
    "    contain data points corresponding to labs and sequences from labs contributing \n",
    "    the top X number of plasmids:  1) complete dataframe with all binary variables, \n",
    "    sequences, and labels; 2) dataframe with just the sequence (index is sequence ID); \n",
    "    and 3) dataframe with just the lab ID (index is sequence ID).\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    \n",
    "    labs_grouped = df.groupby(['lab_id']).count().sort_values(by='sequence', \n",
    "                                                              ascending=True)    \n",
    "    labs_grpd_num_plasmid = labs_grouped.loc[labs_grouped['sequence'] <= num_plasmid]\n",
    "    labs_grpd_num_plasmid = labs_grpd_num_plasmid.reset_index()\n",
    "    df_subset_list = labs_grpd_num_plasmid.lab_id.tolist()\n",
    "    df_subset = df.loc[df['lab_id'].isin(df_subset_list)]\n",
    "    print(f\"There are {len(df_subset_list)} labs in this subset dataframe\")\n",
    "    print(f\"Each lab has submitted no more than {num_plasmid} plasmids\")\n",
    "    df_subset_labs_seqs = df_subset[['sequence', 'seq_len', 'lab_id']]\n",
    "    train_seqs_subset = df_subset_labs_seqs.drop(['seq_len','lab_id'], axis=1)\n",
    "    train_labs_subset = df_subset_labs_seqs.drop(['sequence', 'seq_len'], axis=1)\n",
    "    return df_subset_labs_seqs, train_seqs_subset, train_labs_subset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset_lt_10, seqs_subset_lt_10, labs_subset_lt_10 = reduce_df_size_less_than_max(train_values_labels, num_plasmid=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset_lt_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_subset_lt_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_subset_lt_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have our reduced-size dataframe, which is limited to plasmids that have been submitted by labs that have submitted 10 or fewer plasmids to the AddGene database (449 labs in total).  We also have separate dataframes for sequences and labs.\n",
    "\n",
    "Looking at the frequences of lab IDs associated with plasmids, we see that the top-contributing lab represents almost 28% of all contributions in this group of plasmids.  The top 10 labs contribute ~65% of the plasmids in this dataset--meaning the 32 remaining labs contribute the remaining 35% of plasmids in this subset of plasmids from labs contributing at least 200 plasmids to the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_subset_lt_10.value_counts(normalize=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Character-level vectorization:  values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in preparing the data for analysis in the CNN is to tokenize the base pair letters in the sequences and the lab IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_subset_lt_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seqs_subset_lt_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_subset_lt_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(seqs_subset_lt_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_lt_10 = seqs_subset_lt_10.sequence.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_lt_10[:50]   #check format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(seqs_lt_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting max_length of characters in sequences and tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_char = 8500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(lower = False, char_level = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(seqs_lt_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lt_10 = tokenizer.texts_to_sequences(seqs_lt_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lt_10[:50]   #check format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_lt_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lt_10_85 = sequence.pad_sequences(X_lt_10, maxlen=max_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lt_10_85.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_lt_10_85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_lt_10_85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lt_10_85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that the information is properly encoded, we can get the dictionary of tokens with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Found {} unique tokens'.format(len(word_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lab ID vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_subset_lt_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ids_lt_10 = labs_subset_lt_10.lab_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ids_lt_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_lab = Tokenizer(lower = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_lab.fit_on_texts(lab_ids_lt_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_lt_10 = tokenizer_lab.texts_to_sequences(lab_ids_lt_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_lt_10 = np.array(Y_lt_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_lt_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Transform labels to one-hot\n",
    "lb = LabelBinarizer()\n",
    "y_lt_10 = lb.fit_transform(Y_lt_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lt_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_lt_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_lt_10[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lt_10.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train_test_split on this data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lt_10, X_test_lt_10, y_train_lt_10, y_test_lt_10 = train_test_split(X_lt_10_85, y_lt_10, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lt_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_lt_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_lt_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_lt_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_lt_10[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute class weights for training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create class weights for tokenized training data subset\n",
    "\n",
    "from sklearn import utils \n",
    "\n",
    "def class_weights_dict_tokenized(y):\n",
    "    \n",
    "    '''Function to create class weights for a subset of tokenized training labels'''\n",
    "       \n",
    "    # create unique class array from y\n",
    "    classes = np.unique(y)\n",
    "    \n",
    "    # Compute class weights using sklearn module\n",
    "    class_weights = utils.compute_class_weight('balanced', classes, y = np.ravel(y))\n",
    "#     class_list = classes.tolist()\n",
    "#     class_weights_list = class_weights.tolist()\n",
    "#     class_wts_dict = dict(zip(class_list, class_weights_list))\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_lt_10 = class_weights_dict_tokenized(Y_lt_10)\n",
    "class_weights_lt_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(class_weights_lt_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_char = 8500\n",
    "\n",
    "model_3 = Sequential()\n",
    "embedding_dim = 1\n",
    "model_3.add(Embedding(len(word_index) + 1, embedding_dim, input_length=max_char))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.add(layers.Conv1D(filters=32, kernel_size=12, padding='same', activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.add(layers.MaxPooling1D(pool_size=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_3.add(Dropout(0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.add(layers.Conv1D(filters=32, kernel_size=8, padding='same', activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.add(layers.MaxPooling1D(pool_size=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_3.add(Dropout(0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.add(layers.Flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.add(layers.Dense(128, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.add(layers.Dense(len(y_train_lt_10[0]), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.summary()\n",
    "\n",
    "# Model: \"sequential_25\"\n",
    "# _________________________________________________________________\n",
    "# Layer (type)                 Output Shape              Param #   \n",
    "# =================================================================\n",
    "# embedding_25 (Embedding)     (None, 8500, 1)           6         \n",
    "# _________________________________________________________________\n",
    "# conv1d_47 (Conv1D)           (None, 8500, 32)          416       \n",
    "# _________________________________________________________________\n",
    "# max_pooling1d_37 (MaxPooling (None, 4250, 32)          0         \n",
    "# _________________________________________________________________\n",
    "# conv1d_48 (Conv1D)           (None, 4250, 32)          8224      \n",
    "# _________________________________________________________________\n",
    "# max_pooling1d_38 (MaxPooling (None, 2125, 32)          0         \n",
    "# _________________________________________________________________\n",
    "# flatten_22 (Flatten)         (None, 68000)             0         \n",
    "# _________________________________________________________________\n",
    "# dense_44 (Dense)             (None, 128)               8704128   \n",
    "# _________________________________________________________________\n",
    "# dense_45 (Dense)             (None, 449)               57921     \n",
    "# =================================================================\n",
    "# Total params: 8,770,695\n",
    "# Trainable params: 8,770,695\n",
    "# Non-trainable params: 0\n",
    "# _________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "history_3 = model_3.fit(X_train_lt_10, y_train_lt_10, epochs=40, validation_data=(X_test_lt_10, y_test_lt_10), class_weight = class_weights_lt_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_3.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_3.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_viz(history_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_viz(history_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_3.history).plot(figsize=(10, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 3) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.save('my_model_3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations about model_3\n",
    "\n",
    "(placeholder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_4:  plasmids submitted--between 10 and 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting the maximum number of plasmids that a lab has submitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My first effort at reducing the dataset size was to limit the labs to those contributing at least 200 plasmids to the database.  However, even with this relatively large number, there were still over 45000 data points in the data set and 213 labs.  \n",
    "\n",
    "For these runs, I will be focusing on labs submitted between 10-50 plasmids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_df_size_bounded(df, num_plasmid_lower, num_plasmid_upper):\n",
    "    '''\n",
    "    Takes df with all values and targets and returns the following 3 items that only \n",
    "    contain data points corresponding to labs and sequences from labs between X and Y:  \n",
    "    1) complete dataframe with all binary variables, \n",
    "    sequences, and labels; 2) dataframe with just the sequence (index is sequence ID); \n",
    "    and 3) dataframe with just the lab ID (index is sequence ID).\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    \n",
    "    labs_grouped = df.groupby(['lab_id']).count().sort_values(by='sequence', \n",
    "                                                              ascending=True)    \n",
    "    labs_grpd_num_plasmid = labs_grouped.loc[(labs_grouped['sequence'] >= num_plasmid_lower) & (labs_grouped['sequence'] <= num_plasmid_upper)]\n",
    "    labs_grpd_num_plasmid = labs_grpd_num_plasmid.reset_index()\n",
    "    df_subset_list = labs_grpd_num_plasmid.lab_id.tolist()\n",
    "    df_subset = df.loc[df['lab_id'].isin(df_subset_list)]\n",
    "    print(f\"There are {len(df_subset_list)} labs in this subset dataframe\")\n",
    "    print(f\"Each lab has submitted between {num_plasmid_lower} and {num_plasmid_upper} plasmids\")\n",
    "    df_subset_labs_seqs = df_subset[['sequence', 'seq_len', 'lab_id']]\n",
    "    train_seqs_subset = df_subset_labs_seqs.drop(['seq_len','lab_id'], axis=1)\n",
    "    train_labs_subset = df_subset_labs_seqs.drop(['sequence', 'seq_len'], axis=1)\n",
    "    return df_subset_labs_seqs, train_seqs_subset, train_labs_subset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset_10_50, seqs_subset_10_50, labs_subset_10_50 = reduce_df_size_bounded(train_values_labels, num_plasmid_lower=10, num_plasmid_upper=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset_10_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_subset_10_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_subset_10_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_subset_10_50.value_counts(normalize=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Character-level vectorization:  values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in preparing the data for analysis in the CNN is to tokenize the base pair letters in the sequences and the lab IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_subset_10_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seqs_subset_10_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_subset_10_50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(seqs_subset_10_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_10_50 = seqs_subset_10_50.sequence.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_10_50[:50]   #check format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(seqs_10_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(lower = False, char_level = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(seqs_10_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_10_50 = tokenizer.texts_to_sequences(seqs_10_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_10_50[:50]   #check format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_10_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Padding sequences to max_char length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_char = 8500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_10_50_85 = sequence.pad_sequences(X_10_50, maxlen=max_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_10_50_85.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_10_50_85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_10_50_85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_10_50_85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that the information is properly encoded, we can get the dictionary of tokens with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Found {} unique tokens'.format(len(word_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lab ID vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_subset_10_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ids_10_50 = labs_subset_10_50.lab_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ids_10_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_lab = Tokenizer(lower = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_lab.fit_on_texts(lab_ids_10_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_10_50 = tokenizer_lab.texts_to_sequences(lab_ids_10_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_10_50 = np.array(Y_10_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_10_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(Y_10_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Transform labels to one-hot\n",
    "lb = LabelBinarizer()\n",
    "y_10_50 = lb.fit_transform(Y_10_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_10_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_10_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_10_50[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_10_50.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train_test_split on this data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_10_50, X_test_10_50, y_train_10_50, y_test_10_50 = train_test_split(X_10_50_85, y_10_50, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_10_50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_10_50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_10_50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_10_50[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_10_50.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute class weights for training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create class weights for tokenized training data subset\n",
    "\n",
    "from sklearn import utils \n",
    "\n",
    "def class_weights_dict_tokenized(y):\n",
    "    \n",
    "    '''Function to create class weights for a subset of tokenized training labels'''\n",
    "       \n",
    "    # create unique class array from y\n",
    "    classes = np.unique(y)\n",
    "    \n",
    "    # Compute class weights using sklearn module\n",
    "    class_weights = utils.compute_class_weight('balanced', classes, y = np.ravel(y))\n",
    "#     class_list = classes.tolist()\n",
    "#     class_weights_list = class_weights.tolist()\n",
    "#     class_wts_dict = dict(zip(class_list, class_weights_list))\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_10_50 = class_weights_dict_tokenized(Y_10_50)\n",
    "class_weights_10_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(class_weights_10_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model_4 setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_char = 8500\n",
    "\n",
    "model_4 = Sequential()\n",
    "embedding_dim = 1\n",
    "model_4.add(Embedding(len(word_index) + 1, embedding_dim, input_length=max_char))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.add(layers.Conv1D(filters=32, kernel_size=12, padding='same', activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.add(layers.MaxPooling1D(pool_size=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_4.add(Dropout(0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.add(layers.Conv1D(filters=32, kernel_size=8, padding='same', activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.add(layers.MaxPooling1D(pool_size=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_4.add(Dropout(0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.add(layers.Flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.add(layers.Dense(128, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.add(layers.Dense(len(y_train_10_50[0]), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.summary()\n",
    "\n",
    "# Model: \"sequential_28\"\n",
    "# _________________________________________________________________\n",
    "# Layer (type)                 Output Shape              Param #   \n",
    "# =================================================================\n",
    "# embedding_28 (Embedding)     (None, 8500, 1)           6         \n",
    "# _________________________________________________________________\n",
    "# conv1d_51 (Conv1D)           (None, 8500, 32)          416       \n",
    "# _________________________________________________________________\n",
    "# max_pooling1d_41 (MaxPooling (None, 4250, 32)          0         \n",
    "# _________________________________________________________________\n",
    "# conv1d_52 (Conv1D)           (None, 4250, 32)          8224      \n",
    "# _________________________________________________________________\n",
    "# max_pooling1d_42 (MaxPooling (None, 2125, 32)          0         \n",
    "# _________________________________________________________________\n",
    "# flatten_24 (Flatten)         (None, 68000)             0         \n",
    "# _________________________________________________________________\n",
    "# dense_48 (Dense)             (None, 128)               8704128   \n",
    "# _________________________________________________________________\n",
    "# dense_49 (Dense)             (None, 730)               94170     \n",
    "# =================================================================\n",
    "# Total params: 8,806,944\n",
    "# Trainable params: 8,806,944\n",
    "# Non-trainable params: 0\n",
    "# _________________________________________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "history_4 = model_4.fit(X_train_10_50, y_train_10_50, epochs=20, validation_data=(X_test_10_50, y_test_10_50), class_weight = class_weights_10_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_4.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_4.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_viz(history_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_viz(history_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_4.history).plot(figsize=(10, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 0.1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.save('my_model_4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations about model_4\n",
    "\n",
    "(placeholder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_4a:  plasmids submitted--between 10 and 50; dropout layers added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model_4a setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_char = 8500\n",
    "\n",
    "model_4a = Sequential()\n",
    "embedding_dim = 1\n",
    "model_4a.add(Embedding(len(word_index) + 1, embedding_dim, input_length=max_char))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4a.add(layers.Conv1D(filters=32, kernel_size=12, padding='same', activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4a.add(layers.MaxPooling1D(pool_size=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4a.add(Dropout(0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4a.add(layers.Conv1D(filters=32, kernel_size=8, padding='same', activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4a.add(layers.MaxPooling1D(pool_size=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4a.add(Dropout(0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4a.add(layers.Flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4a.add(layers.Dense(128, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4a.add(layers.Dense(len(y_train_10_50[0]), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4a.summary()\n",
    "\n",
    "# Model: \"sequential_30\"\n",
    "# _________________________________________________________________\n",
    "# Layer (type)                 Output Shape              Param #   \n",
    "# =================================================================\n",
    "# embedding_30 (Embedding)     (None, 8500, 1)           6         \n",
    "# _________________________________________________________________\n",
    "# conv1d_55 (Conv1D)           (None, 8500, 32)          416       \n",
    "# _________________________________________________________________\n",
    "# max_pooling1d_45 (MaxPooling (None, 4250, 32)          0         \n",
    "# _________________________________________________________________\n",
    "# dropout_28 (Dropout)         (None, 4250, 32)          0         \n",
    "# _________________________________________________________________\n",
    "# conv1d_56 (Conv1D)           (None, 4250, 32)          8224      \n",
    "# _________________________________________________________________\n",
    "# max_pooling1d_46 (MaxPooling (None, 2125, 32)          0         \n",
    "# _________________________________________________________________\n",
    "# dropout_29 (Dropout)         (None, 2125, 32)          0         \n",
    "# _________________________________________________________________\n",
    "# flatten_26 (Flatten)         (None, 68000)             0         \n",
    "# _________________________________________________________________\n",
    "# dense_52 (Dense)             (None, 128)               8704128   \n",
    "# _________________________________________________________________\n",
    "# dense_53 (Dense)             (None, 730)               94170     \n",
    "# =================================================================\n",
    "# Total params: 8,806,944\n",
    "# Trainable params: 8,806,944\n",
    "# Non-trainable params: 0\n",
    "# _________________________________________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4a.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "history_4a = model_4a.fit(X_train_10_50, y_train_10_50, epochs=20, validation_data=(X_test_10_50, y_test_10_50), class_weight = class_weights_10_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_4a.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_4a.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_viz(history_4a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_viz(history_4a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_4a.history).plot(figsize=(10, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 3) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4a.save('my_model_4a.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations about model_4a\n",
    "\n",
    "This model was exactly the same as model_4, but with the two dropout layers added back in.  It is shocking to see just how much different the results are with and without dropout layers.  While the validation accuracy of model_4 was quite poor relative to other models (albeit with many fewer labs) the addition of dropout layers drove the validation accuracy to zero!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_5:  plasmid length less than 15000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting lab IDs in a vertical format, rather than as column headers\n",
    "lab_ids = pd.DataFrame(train_labels.idxmax(axis=1), columns=['lab_id'])\n",
    "lab_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reducing dataframe size to increase the speed of training models\n",
    "\n",
    "For these model runs, I'm focusing on the other end of the lab submission frequency spectrum:  labs submitting fewer plasmids. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values_df = train_values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values_df['seq_len'] = train_values_df.sequence.apply(len)\n",
    "train_values_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding seq length and lab_id columns to train_values df, to allow selection of subset of plasmids (number of plasmids per lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values_labels = pd.concat([train_values_df, lab_ids], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_dataset = dataset[['A','D']].copy()\n",
    "\n",
    "train_vals_labs_seq_len = train_values_labels[['sequence', 'seq_len', 'lab_id']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vals_labs_seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting plasmid length to be <= 15000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to see if results are better with plasmids less than a certain length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to select subset dataframe for plasmids up to a certain length\n",
    "\n",
    "def reduce_df_by_seq_len(df, len_plasmid_upper=None, len_plasmid_lower=0):\n",
    "    '''\n",
    "    Takes df with all values and targets and returns the following 3 items that only \n",
    "    contain data points corresponding to labs and sequences from labs between X and Y:  \n",
    "    1) complete dataframe with all binary variables, \n",
    "    sequences, and labels; 2) dataframe with just the sequence (index is sequence ID); \n",
    "    and 3) dataframe with just the lab ID (index is sequence ID).\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    \n",
    "    df_seq_len = df[['sequence', 'seq_len', 'lab_id']].copy()\n",
    "    \n",
    "    plasmid_len = df_seq_len.sort_values(by=['seq_len'], ascending=True) \n",
    "    plasmid_len_subset = plasmid_len.loc[(plasmid_len['seq_len'] >= len_plasmid_lower) & (plasmid_len['seq_len'] <= len_plasmid_upper)]\n",
    "    \n",
    "    df_subset_labs_seqs = plasmid_len_subset\n",
    "    \n",
    "    train_seqs_subset = df_subset_labs_seqs.drop(['seq_len','lab_id'], axis=1)\n",
    "    train_labs_subset = df_subset_labs_seqs.drop(['sequence', 'seq_len'], axis=1)\n",
    "    \n",
    "    return df_subset_labs_seqs, train_seqs_subset, train_labs_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset_seqs_15000, train_seqs_subset_15000, train_labs_subset_15000 = reduce_df_by_seq_len(train_values_labels, len_plasmid_upper=15000, len_plasmid_lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset_seqs_15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seqs_subset_15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labs_subset_15000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Character-level vectorization:  values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in preparing the data for analysis in the CNN is to tokenize the base pair letters in the sequences and the lab IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seqs_subset_15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_seqs_subset_15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seqs_subset_15000.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_seqs_subset_15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_lt_15k = train_seqs_subset_15000.sequence.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_lt_15k[:50]   #check format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(seqs_lt_15k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting max_length of characters in sequences and tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_char = 8500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(lower = False, char_level = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(seqs_lt_15k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lt_15k = tokenizer.texts_to_sequences(seqs_lt_15k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lt_15k[:50]   #check format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_lt_15k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lt_15k_85 = sequence.pad_sequences(X_lt_15k, maxlen=max_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lt_15k_85.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_lt_15k_85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_lt_15k_85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lt_15k_85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that the information is properly encoded, we can get the dictionary of tokens with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Found {} unique tokens'.format(len(word_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lab ID vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labs_subset_15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ids_lt_15k = train_labs_subset_15000.lab_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ids_lt_15k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_lab = Tokenizer(lower = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_lab.fit_on_texts(lab_ids_lt_15k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_lt_15k = tokenizer_lab.texts_to_sequences(lab_ids_lt_15k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_lt_15k = np.array(Y_lt_15k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_lt_15k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(Y_lt_15k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Transform labels to one-hot\n",
    "lb = LabelBinarizer()\n",
    "y_lt_15k = lb.fit_transform(Y_lt_15k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lt_15k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_lt_15k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_lt_15k[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lt_15k.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train_test_split on this data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lt_15k, X_test_lt_15k, y_train_lt_15k, y_test_lt_15k = train_test_split(X_lt_15k_85, y_lt_15k, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lt_15k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_lt_15k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_lt_15k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_lt_15k[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_lt_15k.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute class weights for training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create class weights for tokenized training data subset\n",
    "\n",
    "from sklearn import utils \n",
    "\n",
    "def class_weights_dict_tokenized(y):\n",
    "    \n",
    "    '''Function to create class weights for a subset of tokenized training labels'''\n",
    "       \n",
    "    # create unique class array from y\n",
    "    classes = np.unique(y)\n",
    "    \n",
    "    # Compute class weights using sklearn module\n",
    "    class_weights = utils.compute_class_weight('balanced', classes, y = np.ravel(y))\n",
    "#     class_list = classes.tolist()\n",
    "#     class_weights_list = class_weights.tolist()\n",
    "#     class_wts_dict = dict(zip(class_list, class_weights_list))\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_lt_15k = class_weights_dict_tokenized(Y_lt_15k)\n",
    "class_weights_lt_15k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(class_weights_lt_15k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model_5 setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_char = 8500\n",
    "\n",
    "model_5 = Sequential()\n",
    "embedding_dim = 1\n",
    "model_5.add(Embedding(len(word_index) + 1, embedding_dim, input_length=max_char))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.add(layers.Conv1D(filters=32, kernel_size=12, padding='same', activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.add(layers.MaxPooling1D(pool_size=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_5.add(Dropout(0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.add(layers.Conv1D(filters=32, kernel_size=8, padding='same', activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.add(layers.MaxPooling1D(pool_size=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_5.add(Dropout(0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.add(layers.Flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.add(layers.Dense(128, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.add(layers.Dense(len(y_train_lt_15k[0]), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing a early stopping callback. Monitoring the val_loss, if the val_loss stops to decrease\n",
    "# the training will aborted.\n",
    "# callback_early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile from batches 2 to 20\n",
    "# Using the callback to profile the training.\n",
    "# tb_callback = tf.keras.callbacks.TensorBoard(log_dir='./log_dir/',\n",
    "#                                              profile_batch='2, 20')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.summary()\n",
    "\n",
    "\n",
    "# Model: \"sequential_31\"\n",
    "# _________________________________________________________________\n",
    "# Layer (type)                 Output Shape              Param #   \n",
    "# =================================================================\n",
    "# embedding_31 (Embedding)     (None, 8500, 1)           6         \n",
    "# _________________________________________________________________\n",
    "# conv1d_57 (Conv1D)           (None, 8500, 32)          416       \n",
    "# _________________________________________________________________\n",
    "# max_pooling1d_47 (MaxPooling (None, 4250, 32)          0         \n",
    "# _________________________________________________________________\n",
    "# conv1d_58 (Conv1D)           (None, 4250, 32)          8224      \n",
    "# _________________________________________________________________\n",
    "# max_pooling1d_48 (MaxPooling (None, 2125, 32)          0         \n",
    "# _________________________________________________________________\n",
    "# flatten_27 (Flatten)         (None, 68000)             0         \n",
    "# _________________________________________________________________\n",
    "# dense_54 (Dense)             (None, 128)               8704128   \n",
    "# _________________________________________________________________\n",
    "# dense_55 (Dense)             (None, 1312)              169248    \n",
    "# =================================================================\n",
    "# Total params: 8,882,022\n",
    "# Trainable params: 8,882,022\n",
    "# Non-trainable params: 0\n",
    "# _________________________________________________________________\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "history_5 = model_5.fit(X_train_lt_15k, y_train_lt_15k, epochs=20, validation_data=(X_test_lt_15k, y_test_lt_15k), class_weight = class_weights_lt_15k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_5.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_5.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_viz(history_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_viz(history_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_5.history).plot(figsize=(10, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 4) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.save('my_model_5.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations about model\n",
    "\n",
    "(placeholder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Results and Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original analysis (code for these models can be found in the Appendix)\n",
    " \n",
    "Because of time constraints, I was only able to pursue a few different neural network modeling approaches for the capstone project.  Some key observations:\n",
    "* My CNN models followed the same basic structure of Embedding layer, then a stack of Conv1D/MaxPooling1D/Dropout(0.2), followed by another stack of Conv1D/MaxPooling1D/Dropout(0.2), then a flattening layer, a dense layer, and finally an output layer. (Note:  The dropout layer was included in models 2-6 after the seeing a performance improvement upon including it in model_1b).  \n",
    "* Reducing the number of inputs or reducing the dimensionality in the layers through filter size and/or kernel size not only helped the model to run faster, but also seemed to give results that were just as good if not slightly better than larger models.\n",
    "  * Increasing the number of filters didn't seem to improve validation accuracy much, but they did appear to increase overfitting. \n",
    "  * Adding a *second* convolutional layer to an existing stack of a single 1D convolutional layer/maxpooling layer/dropout layer didn't seem to give better results.  (I had read that, rather than using a larger kernel, it can be better to just add a second Conv1D layer right below and use smaller kernels for each, but this did not seem to improve results.)\n",
    "* Looking across all of the results for model_1 through model_6, I'm struck by how similar the outcomes are, even after modifying some of the hyperparameters, layer structure (adding dropout layers, adding additional Conv1D layers), and trying different maximum character lengths.  \n",
    "* A couple of explanations for the similar results across all models come to mind:\n",
    "  * Perhaps the most obvious is that the modifications made to the model don't have much of an impact on the overall performance for this particular problem\n",
    "  * Sequences that exceed the max_char limit may contain more useful information towards the end of the plasmid; even though (or maybe because) such long sequences constitute a small percentage of all plasmids, they might still contain unique information that could improve the performance of the model\n",
    "  * Perhaps the most important potential explanation has to do with the characteristics of the labs included in this analysis  \n",
    "    * Having only 42 of the 1314 labs represented probably hinders the ability of the neural network to connect variations in sequences and positions to the labs that produced them\n",
    "    * While such a severe skew in terms of the number of plasmids contributed by labs would make regression analysis very challenging, all of that variability across the labs and plasmids in the remaining 1270 or so labs would probably increase the ability of the neural network to recognize patterns \n",
    "    * By including only the labs that have contributed a large number of plasmids, I suspect that this makes the neural network's job more difficult:  these labs have each contributed lots of plasmids--some have contributed thousands--and so the variety within each lab's portfolio probably makes it more difficult for the neural network to resolve smaller features within the sequences and connect them to different labs\n",
    "* Future work should include an analysis of all labs, even those contributing very few sequences, to see whether hyperparameter tuning approaches have a bigger effect, as well as to compare the results using the same model architecture as those already run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updated models\n",
    "\n",
    "The 1D CNN models worked fairly well on the smaller dataset of labs that had submitted at least 200 plasmids (42 labs in all), with a training accuracy of over 90% in some cases and a validation accuracy of around 75%.  Unfortunately, the models did extremely poorly as the dataset was changed to focus on labs that had each submitted a smaller number of plasmids.  \n",
    "\n",
    "Aside from the obvious consideration that 1D CNNs may not be the best modeling choice--an RNN with LSTM might well perform better--there are a couple of things to consider:\n",
    "\n",
    "1. Because I was more focused on completing my capstone project than on submitting entries into the competition, I left out a very important element that would need to be included for a competition submission:  setting up the models to issue predictions as the top 10 most-likely labs to have produced each plasmid, rather than only predicting one lab per sample.  The reason I didn't set up the models this way for the capstone is because I started with a subset of plasmids from only 40 labs (as opposed to the entire dataset, which contains plasmids from a total of 1314 labs), and I wanted to see how the model performed \n",
    "\n",
    "2. Sequences were padded to a max length of 8500.  Sequences longer than 8500 were truncated to that length.  Thus, information beyond 8500 DNA base pairs was not captured.  This is potentially problematic, because there are thousands of plasmids in this dataset that are significantly larger than this.  Larger plasmids are likely to contain important additional information that could help pinpoint labs of origin.  I did try to modify my code to create batches of variable length sequences (to avoid padding every sequence to 8500 or beyond) to allow for longer sequences while reducing computational load, but was unsuccessful in my efforts to feed variable-length batches into my models in the time available.  \n",
    "\n",
    "3.  Many plasmids contain genes on both strands of DNA in the plasmid, but typically only one of the two DNA strand's sequences is provided in genetic databases.  This is not usually a problem:  most, if not all, of a plasmid's information is contained on the primary strand; further, the complementarity of DNA strands means that the second strand's sequence can be determined from the first strand.  However, incorporating the additional seuqence information from the complementary (\"anti-sense\") strand adds complexity to the analysis.  Some sequence analysis approaches (e.g., RNN) allow for reverse-sequence reading, but I have not yet pursued these approaches.  For me, the first priority was to explore modeling approaches and get my code up and running before refining the models to incorporate these and other issues.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions and Future Work "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions from original analysis\n",
    "\n",
    "For this project, I was able to create an interesting and challenging data science project that combined my college-level understanding of molecular biology cloning with my growing data science tool kit and knowledge base.  It was fascinating to revisit the topic of cloning and also be able to bring some of my previous knowledge and experience to the problem.  Researching the topic of sequence and lab-of-origin prediction for the project also furthered my knowledge of neural networks more than I had expected to do at the end of the Flatiron program!  \n",
    "\n",
    "I feel that my neural networks so far have done a good job in predicting labs of origin for a subset of labs and sequences (much better than chance, as opposed to an ensemble method such as random forest), although I feel that I have only scratched the surface of possible approaches and optimizations.  As will be well-known to anyone who has worked with neural networks extensively, hyperparameter tuning is a vast landscape of potential permutations and variations that can consume a lot of time in model development and testing.  And as I have learned during my data science program, there is always more work that can be done to tweak models and explore alternative approaches, but deadlines are a reality.  Given this, the following are possible next steps for this work:\n",
    "\n",
    "* As indicated in the last bullet above, running the existing model architecture with a wider range of labs would be the next step \n",
    "* A Recurrent Neural Network (RNN) using LSTM layers\n",
    "* Additional parameter tweaking of the Convolutional 1D neural network described\n",
    "* Folding in the binary features along with the sequence data (which has been the sole focus of the neural network portion of this project\n",
    "* Testing the most promising models on the entire dataset\n",
    "* Setting max_char from the end of the sequence rather than the beginning (in other words, for max_char = 5000, taking the last 5000 base pairs rather than the first 5000 base pairs\n",
    "* Breaking up a large sequence from a lab into smaller sequences (each one being a separate row but having the same sequence ID and lab ID in the labels) and running those through the model with a max_char limit\n",
    "\n",
    "Another possible approach besides neural networks could be to find a fairly comprehensive library of sequences used in plasmid production, turn these sequences into features, and then run those features through a random forest or other ensemble models.  The problem with this approach, however, is that this approach on its own cannot evaluate where the sequences are along the length of the plasmid relative to each other.  This spatial aspect is likely an important element of a lab's 'fingerprint' on a plasmid; not being able to analyze this component will likely hinder the model's predictive ability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions for updated models\n",
    "\n",
    "While I have not yet been able to access code for the winning models (all of which are in a ~20 GB zip file for which the download repeatedly fails) the synopses provided by the winners reveals a range of approaches that the teams employed.  These approaches were quite sophisticated and involved many steps, inclulding as preparing a file of ~1000 sequences of known markers most commonly used in plasmids, then feeding the markers, plasmid sequences, and some or all of the other features in the dataset into the models.  Significant domain expertise, time, and computational power is likely to be required even to replicate their efforts--though it could be a useful exercise just to see if it's possible to even run the models on my computer.  \n",
    "\n",
    "One very interesting thing I recently noticed is the fact that altlabs has shown good results with RNN-LSTM models over the last few years, but the top 5 models in the GEAC competition used some form of CNN (mostly 1D, but one 2D CNN as well).  I don't think that any of the winning groups used RNNs based on the summaries of their analyses; if I'm able to download the zip file, I will be looking for more information about how they accomplished their results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models from Original Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_4:  Increasing max_char to 10000 and using smaller filter numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running the model on 5000 max characters, increasing the filter numbers in the convolutional layers slightly diminished accuracy.  I'd like to see what happens with a larger max_char but with the smaller filter numbers as in model_2.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the reduced size dataframe of sequences that we start with:\n",
    "seqs_subset_200.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = seqs_subset_200.sequence.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting max_length of characters in sequences and tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_char = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sequence.pad_sequences(X, maxlen=max_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = Sequential()\n",
    "embedding_dim = 8\n",
    "model_4.add(Embedding(len(word_index) + 1, embedding_dim, input_length=max_char))\n",
    "model_4.add(layers.Conv1D(filters=64, kernel_size=12, padding='same', activation='relu'))\n",
    "model_4.add(layers.MaxPooling1D(pool_size=2))\n",
    "model_4.add(Dropout(0.2))\n",
    "model_4.add(layers.Conv1D(filters=32, kernel_size=8, padding='same', activation='relu'))\n",
    "model_4.add(layers.MaxPooling1D(pool_size=2))\n",
    "model_4.add(Dropout(0.2))\n",
    "model_4.add(layers.Flatten())\n",
    "model_4.add(layers.Dense(128, activation='relu'))\n",
    "model_4.add(layers.Dense(len(y[0]), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_4.pop()\n",
    "# model_4.pop()\n",
    "# print(len(model_4.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_4 = model_4.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test), class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.save('my_model_4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history_4.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy = history_4.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_4.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_viz(history_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_viz(history_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_4.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_4.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1.6) # set the vertical range to [0-1]\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations about model_4\n",
    "\n",
    "In model_4, I increased the max_char value to 10000 and used a similar structure to previous models (2 Conv1D layers with MaxPooling and Dropout), but with a smaller number of filters (64 in first Conv1D layer and 32 in second Conv1D layer) but increased kernel size.  \n",
    "Validation accuracy was about the same as previous models, but this approach did seem to reduce overfitting just a bit (smaller max training accuracy and a little less divergence of the plots for training and validation loss and accuracy, respectively). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_5:  Adding another convolution layer to each of the two conv1D layer stacks and reducing kernel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = Sequential()\n",
    "embedding_dim = 8\n",
    "model_5.add(Embedding(len(word_index) + 1, embedding_dim, input_length=max_char))\n",
    "model_5.add(layers.Conv1D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
    "model_5.add(layers.Conv1D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
    "model_5.add(layers.MaxPooling1D(pool_size=2))\n",
    "model_5.add(layers.Conv1D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
    "model_5.add(layers.Conv1D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
    "model_5.add(layers.MaxPooling1D(pool_size=2))=\n",
    "model_5.add(layers.Flatten())\n",
    "model_5.add(layers.Dense(128, activation='relu'))\n",
    "model_5.add(layers.Dense(len(y[0]), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2.pop()\n",
    "# model_2.pop()\n",
    "# print(len(model_2.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_5 = model_5.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test), class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.save('my_model_5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history_5.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy = history_5.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_5.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_viz(history_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_viz(history_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_5.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_5.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 2) # set the vertical range to [0-1]\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations about model_5\n",
    "\n",
    "In model_5, I kept the max_char at 10000 and added another convolutional layer to each iteration of Conv1D/MaxPooling/Dropout to see whether the result might improve.  It didn't.  Validation performance was no better than previous models but there was more evidence of overfitting.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_6:  Increasing max_char to 20000 and using smaller filter numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the reduced size dataframe of sequences that we start with:\n",
    "seqs_subset_200.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = seqs_subset_200.sequence.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting max_length of characters in sequences and tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_char = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sequence.pad_sequences(X, maxlen=max_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6 = Sequential()\n",
    "embedding_dim = 8\n",
    "model_6.add(Embedding(len(word_index) + 1, embedding_dim, input_length=max_char))\n",
    "model_6.add(layers.Conv1D(filters=64, kernel_size=4, padding='same', activation='relu'))\n",
    "model_6.add(layers.MaxPooling1D(pool_size=2))\n",
    "model_6.add(layers.Conv1D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
    "model_6.add(layers.MaxPooling1D(pool_size=2))\n",
    "model_6.add(layers.Flatten())\n",
    "model_6.add(layers.Dense(128, activation='relu'))\n",
    "model_6.add(layers.Dense(len(y[0]), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_6.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_6.pop()\n",
    "# model_6.pop()\n",
    "# print(len(model_6.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_6 = model_6.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test), class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.save('my_model_6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history_6.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy = history_6.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_6.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_viz(history_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_viz(history_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_6.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_6.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1.6) # set the vertical range to [0-1]\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations about model_6\n",
    "\n",
    "In model_6, I increase max_char to 20000, but otherwise used the same structure and values as for model_5.  As with all of the previous CNN models I ran in this notebook, the training and validation loss and accuracy results over 5 epochs in this model look very similar to those in the previous models.  After 2 or 3 epochs, overfitting becomes very apparent and validation accuracy plateaus.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option to run existing model(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From stackoverflow:  https://stackoverflow.com/questions/42763094/how-to-save-final-model-using-keras\n",
    "\n",
    "You can use ```model.save(filepath)``` to save a Keras model into a single HDF5 file which will contain:\n",
    "\n",
    "the architecture of the model, allowing to re-create the model.\n",
    "the weights of the model.\n",
    "the training configuration (loss, optimizer)\n",
    "the state of the optimizer, allowing to resume training exactly where you left off.\n",
    "In your Python code probable the last line should be:\n",
    "\n",
    "```model.save(\"m.hdf5\")```\n",
    "This allows you to save the entirety of the state of a model in a single file. Saved models can be reinstantiated via ```keras.models.load_model()```.\n",
    "\n",
    "The model returned by ```load_model()``` is a compiled model ready to be used (unless the saved model was never compiled in the first place).\n",
    "\n",
    "```model.save()``` arguments:\n",
    "\n",
    "filepath: String, path to the file to save the weights to.\n",
    "overwrite: Whether to silently overwrite any existing file at the target location, or provide the user with a manual prompt.\n",
    "include_optimizer: If True, save optimizer's state together.\n",
    "\n",
    "(answered Dec 12 '18 by\n",
    "prosti)\n",
    "\n",
    "\n",
    "```python\n",
    "from keras.models import load_model\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilities and top 10 lab probabilities for each result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_probas_train = model.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model_probas_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_probas_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model_probas_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_probas_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_probas = np.sort(model_probas_train[0].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model_probas_train[0].copy()\n",
    "\n",
    "top_10 = np.argsort(a)\n",
    "top_10[32:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return indices (labs) of top 10 probabilities for each result\n",
    "\n",
    "def return_top_10_labs_single(arr):\n",
    "    arr_copy = arr.copy()\n",
    "    return np.argsort(arr_copy)[32:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_top_10_labs_single(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_top_10_labs_all(arr):\n",
    "    arr_copy = arr.copy()\n",
    "    return np.argsort(arr_copy)[:, 32:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_labs_all = return_top_10_labs(all_probs)\n",
    "top_10_labs_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(top_10_labs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predicts = model.predict_classes(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predicts  # this is what the model predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_predicts[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_inv  # these were the actual lab id values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can we write a function that yields a boolean of whether true value is found within the top 10 predicted labs?\n",
    "\n",
    "# is y_train_inv[i] in top_10_labs_all[i]?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "print_stop = 40\n",
    "counter = 0\n",
    "top_10_labs_all[counter]\n",
    "\n",
    "\n",
    "for i in (y_train_inv):\n",
    "    if counter < print_stop: \n",
    "        if i in top_10_labs_all[counter]:\n",
    "            print(\"In the top 10?  Yes\")\n",
    "            print(f\"Actual lab: {i}\")\n",
    "            print(f\"Top 10 predicted labs:  {top_10_labs_all[counter]}\")\n",
    "            print()\n",
    "        else:\n",
    "            print(\"In the top 10?  No\")\n",
    "            print(f\"Actual lab: {i}\")\n",
    "            print(f\"Top 10 predicted labs:  {top_10_labs_all[counter]}\")\n",
    "            print()\n",
    "\n",
    "    counter += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stop = 30\n",
    "counter = 0\n",
    "train_predicts[counter]\n",
    "\n",
    "\n",
    "for idx, i in enumerate(y_train_inv):\n",
    "    if idx < print_stop: \n",
    "        if i == train_predicts[idx]:\n",
    "            print(\"Correct lab predicted?  Yes\")\n",
    "            print(f\"Actual lab: {i}\")\n",
    "            print(f\"Predicted lab:  {train_predicts[idx]}\")\n",
    "            print()\n",
    "        else:\n",
    "            print(\"Correct lab predicted?  No\")\n",
    "            print(f\"Actual lab: {i}\")\n",
    "            print(f\"Predicted lab:  {train_predicts[idx]}\")\n",
    "            print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stop = 10000\n",
    "counter = 0\n",
    "top_10_labs_all[counter]\n",
    "\n",
    "matching = []\n",
    "\n",
    "for i in (y_train_inv):\n",
    "    if counter < print_stop: \n",
    "        if i in top_10_labs_all[counter]:\n",
    "            matching.append('True')\n",
    "        else:\n",
    "            matching.append('False')\n",
    "    \n",
    "    counter += 1\n",
    "\n",
    "print(f\"Total number of predictions in sample:  {print_stop}\")\n",
    "print(f\"Number of successful top 10 predictions in sample:  {matching.count('True')}\")\n",
    "print(f\"Number of failed top 10 predictions in sample:  {matching.count('False')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stop = 10000\n",
    "counter = 0\n",
    "# print(train_predicts[counter])\n",
    "\n",
    "matching = []\n",
    "\n",
    "for i in (y_train_inv):\n",
    "    if counter < print_stop: \n",
    "        if i == train_predicts[counter]:\n",
    "            matching.append('True')\n",
    "        else:\n",
    "            matching.append('False')\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "print(f\"Total number of predictions in sample:  {print_stop}\")\n",
    "print(f\"Number of successful predictions in sample:  {matching.count('True')}\")\n",
    "print(f\"Number of failed predictions in sample:  {matching.count('False')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "336px",
    "width": "405px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.467px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
